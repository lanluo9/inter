{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f602c12f",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy.io import savemat\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f8eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>depth</th>\n",
       "      <th>num</th>\n",
       "      <th>cellpose_seg</th>\n",
       "      <th>manual_seg</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>gcamp</th>\n",
       "      <th>time</th>\n",
       "      <th>AWS</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1392</td>\n",
       "      <td>240225</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_2ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1392</td>\n",
       "      <td>240228</td>\n",
       "      <td>V1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_2isi_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1392</td>\n",
       "      <td>240228</td>\n",
       "      <td>V1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_2isi_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1381</td>\n",
       "      <td>240229</td>\n",
       "      <td>V1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_2isi_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1381</td>\n",
       "      <td>240229</td>\n",
       "      <td>V1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_2isi_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mouse    date area  depth  num  cellpose_seg manual_seg  \\\n",
       "175   1392  240225   V1    NaN  003           1.0        NaN   \n",
       "176   1392  240228   V1  200.0  002           1.0        NaN   \n",
       "177   1392  240228   V1  200.0  003           1.0        NaN   \n",
       "178   1381  240229   V1  150.0  002           1.0        NaN   \n",
       "179   1381  240229   V1  150.0  003           1.0        NaN   \n",
       "\n",
       "                        paradigm gcamp    time  AWS note  \n",
       "175       grating_2ori_multisess    6s  1308.0  NaN  NaN  \n",
       "176  grating_8ori_2isi_multisess    6s     NaN  NaN  NaN  \n",
       "177  grating_8ori_2isi_multisess    6s     NaN  NaN  NaN  \n",
       "178  grating_8ori_2isi_multisess    6s     NaN  NaN  NaN  \n",
       "179  grating_8ori_2isi_multisess    6s     NaN  NaN  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_inter = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter/'.replace('\\\\', '/')\n",
    "dir_file = dir_inter + 'adp_dataset_master.xlsx'\n",
    "data_info = pd.read_excel(dir_file)\n",
    "data_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2a5d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area\n",
      "V1    12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# meta = data_info[(data_info.paradigm == 'grating_8ori_2isi_multisess')\n",
    "#                  & (data_info.date == 240229)\n",
    "#                  ]\n",
    "\n",
    "meta = data_info[(data_info.paradigm == 'grating_lindsey_miaomiao')]\n",
    "\n",
    "# meta = data_info[(data_info.paradigm == 'grating')\n",
    "#                  & (data_info.gcamp == '6s') # avoid mixing in gcamp8f\n",
    "#                  & ((data_info.cellpose_seg == True) | (data_info.manual_seg == True)) # ensure segmentation\n",
    "#                  ]\n",
    "\n",
    "meta = meta.reset_index(drop=True)\n",
    "nset = meta.shape[0]\n",
    "print(meta.area.value_counts())\n",
    "# meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c6e2c",
   "metadata": {},
   "source": [
    "# cell filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2deab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "------------------\n",
      "V1_i674_170324_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(73, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 212.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 cells are image driven - with overlap between images, \n",
      "        proportion 0.1 out of 584 cell-stim combos. \n",
      "        1-N image evokes resp from [10  3  7  7 11  4  9 10] cells\n",
      "26 cells are visually driven, \n",
      "        proportion 0.36 out of 73 cells\n",
      "26 cells are vis strict pval, \n",
      "        proportion 0.36 out of 73 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i674_170324_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i689_170323_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(19, 8, 3) (14, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 223.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 152 cell-stim combos. \n",
      "        1-N image evokes resp from [3 2 3 4 1 1 0 4] cells\n",
      "4 cells are visually driven, \n",
      "        proportion 0.21 out of 19 cells\n",
      "0 cells are vis strict pval, \n",
      "        proportion 0.0 out of 19 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i689_170323_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i696_170323_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(73, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 223.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 cells are image driven - with overlap between images, \n",
      "        proportion 0.2 out of 584 cell-stim combos. \n",
      "        1-N image evokes resp from [ 0 19 11 22 19 13 17 15] cells\n",
      "44 cells are visually driven, \n",
      "        proportion 0.6 out of 73 cells\n",
      "0 cells are vis strict pval, \n",
      "        proportion 0.0 out of 73 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i696_170323_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i684_170327_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(31, 8, 3) (14, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 210.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 cells are image driven - with overlap between images, \n",
      "        proportion 0.26 out of 248 cell-stim combos. \n",
      "        1-N image evokes resp from [13  6  6 12  9  7  6  6] cells\n",
      "28 cells are visually driven, \n",
      "        proportion 0.9 out of 31 cells\n",
      "30 cells are vis strict pval, \n",
      "        proportion 0.97 out of 31 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i684_170327_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i711_170503_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(33, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 211.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 cells are image driven - with overlap between images, \n",
      "        proportion 0.18 out of 264 cell-stim combos. \n",
      "        1-N image evokes resp from [6 8 6 5 6 5 6 5] cells\n",
      "13 cells are visually driven, \n",
      "        proportion 0.39 out of 33 cells\n",
      "14 cells are vis strict pval, \n",
      "        proportion 0.42 out of 33 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i711_170503_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i712_170503_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(43, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 207.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 cells are image driven - with overlap between images, \n",
      "        proportion 0.24 out of 344 cell-stim combos. \n",
      "        1-N image evokes resp from [13 11  9  6 11  8  9 15] cells\n",
      "31 cells are visually driven, \n",
      "        proportion 0.72 out of 43 cells\n",
      "31 cells are vis strict pval, \n",
      "        proportion 0.72 out of 43 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i712_170503_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i574_170510_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(94, 8, 3) (14, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 213.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 cells are image driven - with overlap between images, \n",
      "        proportion 0.27 out of 752 cell-stim combos. \n",
      "        1-N image evokes resp from [29 25 28 18 19 31 22 32] cells\n",
      "79 cells are visually driven, \n",
      "        proportion 0.84 out of 94 cells\n",
      "82 cells are vis strict pval, \n",
      "        proportion 0.87 out of 94 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i574_170510_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i720_170808_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(55, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 213.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 cells are image driven - with overlap between images, \n",
      "        proportion 0.23 out of 440 cell-stim combos. \n",
      "        1-N image evokes resp from [ 8  8 14 17 12 20 14 10] cells\n",
      "41 cells are visually driven, \n",
      "        proportion 0.75 out of 55 cells\n",
      "41 cells are vis strict pval, \n",
      "        proportion 0.75 out of 55 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i720_170808_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i738_170810_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(16, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 222.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 cells are image driven - with overlap between images, \n",
      "        proportion 0.33 out of 128 cell-stim combos. \n",
      "        1-N image evokes resp from [8 5 0 5 2 9 7 6] cells\n",
      "15 cells are visually driven, \n",
      "        proportion 0.94 out of 16 cells\n",
      "0 cells are vis strict pval, \n",
      "        proportion 0.0 out of 16 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i738_170810_002-003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "------------------\n",
      "V1_i739_170811_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(35, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 210.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 cells are image driven - with overlap between images, \n",
      "        proportion 0.17 out of 280 cell-stim combos. \n",
      "        1-N image evokes resp from [ 3  2  6  7  7  8  5 10] cells\n",
      "27 cells are visually driven, \n",
      "        proportion 0.77 out of 35 cells\n",
      "28 cells are vis strict pval, \n",
      "        proportion 0.8 out of 35 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i739_170811_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i745_170816_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(66, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 225.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 cells are image driven - with overlap between images, \n",
      "        proportion 0.17 out of 528 cell-stim combos. \n",
      "        1-N image evokes resp from [13 12 12  0 15 12 16 10] cells\n",
      "52 cells are visually driven, \n",
      "        proportion 0.79 out of 66 cells\n",
      "0 cells are vis strict pval, \n",
      "        proportion 0.0 out of 66 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i745_170816_002-003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i746_170826_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(49, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \n",
      " N possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 224.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 cells are image driven - with overlap between images, \n",
      "        proportion 0.18 out of 392 cell-stim combos. \n",
      "        1-N image evokes resp from [ 6  9 13  0 13  9  6 13] cells\n",
      "44 cells are visually driven, \n",
      "        proportion 0.9 out of 49 cells\n",
      "0 cells are vis strict pval, \n",
      "        proportion 0.0 out of 49 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i746_170826_002-003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# session_mode = 'multi session' # no need to append irun to dir_sub\n",
    "\n",
    "## set up logging\n",
    "plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "logging.basicConfig(filename=r'C:\\Users\\ll357\\Documents\\inter\\data\\vis_driven.log'.replace('\\\\', '/'), level=logging.DEBUG)\n",
    "logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "logging.info(str(datetime.now()))\n",
    "\n",
    "for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "    # clear_output(wait=True)\n",
    "    logging.info(f'set {i+1} of {nset}')\n",
    "    mouse = meta.iloc[i].mouse.astype(str)\n",
    "    date = meta.iloc[i].date.astype(str)\n",
    "    area = meta.iloc[i].area\n",
    "    irun = meta.iloc[i].num # already a string due to concat lindsey's grating 8ori data\n",
    "    logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "    ## check if resp_base_trialwise exists\n",
    "    ## load data\n",
    "    logging.info('waiting for mat')\n",
    "    print('waiting for mat')\n",
    "    print('------------------')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            dir_sub = area + '_i' + mouse + '_' + date\n",
    "            if session_mode == 'single session':\n",
    "                dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "            print(dir_sub)\n",
    "            try: # manual seg data has no suffix '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            except: # cellpose seg data has suffix '_cellpose'\n",
    "                dir_sub += '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            logging.info('mat loaded')\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(60)\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "        isi_mode = 'only one isi'\n",
    "        print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "        dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "        dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "        isi_mode = 'grat_8ori_3isi'\n",
    "        print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "        dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "        dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "        print('to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \\n N possible target orientations will cover all needed cells')\n",
    "\n",
    "    ## stats\n",
    "    if isi_mode == 'only one isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_ad_trial.shape[0]\n",
    "        nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base_trial[icell, istim]\n",
    "                stim_cell = dfof_ad_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "    elif isi_mode == 'grat_8ori_3isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_tg_trial.shape[0]\n",
    "        nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base2_trial[icell, istim]\n",
    "                stim_cell = dfof_tg_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "\n",
    "    # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "    p_sig = 0.05\n",
    "    if area == 'LI':\n",
    "        p_sig = 0.1 # relax sig for LI. used for vis_driven_ttest_bonferroni_jeff.mat\n",
    "    evoked_thresh = 0.05\n",
    "    img_driven = (p_ttest < p_sig) & (evoked > evoked_thresh)\n",
    "    img_driven_msg = f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "        proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "        1-N image evokes resp from {np.sum(img_driven, axis=0)} cells'\n",
    "    logging.info(img_driven_msg)\n",
    "    print(img_driven_msg)\n",
    "\n",
    "    t = np.sum(img_driven, axis=1)\n",
    "    logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "    # visually driven cells\n",
    "    # NOTE changed to: driven by any image (pass t-test to any stim2, but with bonferroni correction) AND amp threshold. \n",
    "    loosen_sig = 1 # do not loosen, set ratio = 1\n",
    "    p_bonferroni_corrected = loosen_sig * p_sig / nstim # number of possible stim2\n",
    "    vis_driven = ((np.sum(p_ttest < p_bonferroni_corrected, axis=1) > 0) # any stim2 passes t-test\n",
    "                & (np.sum(evoked > evoked_thresh, axis=1) > 0) # AND any stim2 evokes resp > thresh\n",
    "                ) # bc vis filter = p_bonf & evoked_thresh, vis bool wont match vis_pval exactly in df_tidy! \n",
    "    vis_driven_msg = f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells'\n",
    "    logging.info(vis_driven_msg)\n",
    "    print(vis_driven_msg)\n",
    "\n",
    "    # break\n",
    "\n",
    "    ## construct vis_strict based on vis_pval\n",
    "    filter_cell_vis_pval = np.min(p_ttest, axis=1) # min pval across all stim\n",
    "    filter_cell_vis_strict = filter_cell_vis_pval < p_bonferroni_corrected\n",
    "    vis_strict_msg = f'{filter_cell_vis_strict.sum()} cells are vis strict pval, \\n\\\n",
    "        proportion {np.round(filter_cell_vis_strict.sum()/ncell, 2)} out of {ncell} cells'\n",
    "    print(vis_strict_msg)\n",
    "\n",
    "    ## save\n",
    "    vis_driven_re = {}\n",
    "    # vis_driven_re['p_anova'] = p_anova\n",
    "    # vis_driven_re['p_kruskal'] = p_kruskal\n",
    "    vis_driven_re['p_ttest'] = p_ttest\n",
    "    vis_driven_re['evoked'] = evoked\n",
    "    vis_driven_re['p_sig'] = p_sig\n",
    "    vis_driven_re['p_bonferroni_corrected'] = p_bonferroni_corrected\n",
    "    vis_driven_re['vis_driven'] = vis_driven\n",
    "    vis_driven_re['vis_strict'] = filter_cell_vis_strict\n",
    "    vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "    os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "    print(os.getcwd())\n",
    "    # savemat(\"vis_driven_ttest_bonferroni_jeff.mat\", vis_driven_re)\n",
    "    savemat(\"vis_strict_ttest_bonferroni_jeff.mat\", vis_driven_re)\n",
    "    \n",
    "    # with open('vis_driven_ttest_bonferroni.pickle', 'wb') as f:\n",
    "    with open('vis_strict_ttest_bonferroni.pickle', 'wb') as f:\n",
    "        pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a103ca42",
   "metadata": {},
   "source": [
    "# depre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6659cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323 200721\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n"
     ]
    }
   ],
   "source": [
    "# # meta = pd.read_excel(mat_inter_path + 'adp_dataset_master.xlsx')\n",
    "\n",
    "# # date_str = str(200721)\n",
    "# # mouse_str = meta.loc[meta['date'] == int(date_str), 'mouse'].values#[0]\n",
    "# # area_str = meta.loc[meta['date'] == int(date_str), 'area'].values[0]\n",
    "# # if len(mouse_str) > 1:\n",
    "# #     print('duplicate dates with maybe different mouse. select which mouse?')\n",
    "# # else:\n",
    "# #     mouse_str = str(mouse_str[0])\n",
    "# # print(mouse_str, date_str)\n",
    "\n",
    "# try:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + '_cellpose'\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# except:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + ''\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#     mode = 'only one isi'\n",
    "#     print(f'mode is {mode} (only one isi, grat_SF or bunny)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#     dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#     dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#     mode = 'grat_8ori_3isi'\n",
    "#     print(f'mode is {mode} (grating with 8 orientations and 3 ISI)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#     dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#     dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#     print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b51367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 345.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# if mode == 'only one isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_ad_trial.shape[0]\n",
    "#     nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base_trial[icell, istim]\n",
    "#             stim_cell = dfof_ad_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "# elif mode == 'grat_8ori_3isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_tg_trial.shape[0]\n",
    "#     nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base2_trial[icell, istim]\n",
    "#             stim_cell = dfof_tg_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395531aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 cells are visually driven, \n",
      "    proportion 0.67 out of 39 cells\n",
      "29 cells are image driven - with overlap between images, \n",
      "    proportion 0.09 out of 312 cell-stim combos. \n",
      "    1-N image evokes resp from [4 2 6 1 3 2 5 6] cells\n",
      "img driven cells are driven by [1 2 2 1 2 1 1 1 2 1 2 1 4 1 1 1 1 3 1] images\n"
     ]
    }
   ],
   "source": [
    "# # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "# p_sig = 0.05\n",
    "# vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "# print(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#     proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "# # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "# img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "# print(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#     proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#     1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "# t = np.sum(img_driven, axis=1)\n",
    "# print(f'img driven cells are driven by {t[t>0]} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabf9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\duhs-user-nc1.dhe.duke.edu\\dusom_glickfeldlab\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721\n"
     ]
    }
   ],
   "source": [
    "# vis_driven_re = {}\n",
    "# vis_driven_re['p_anova'] = p_anova\n",
    "# vis_driven_re['p_kruskal'] = p_kruskal\n",
    "# vis_driven_re['p_ttest'] = p_ttest\n",
    "# vis_driven_re['evoked'] = evoked\n",
    "# vis_driven_re['p_sig'] = p_sig\n",
    "# vis_driven_re['vis_driven'] = vis_driven\n",
    "# vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "# os.chdir(os.path.join(mat_inter_path, dir_sub))\n",
    "# print(os.getcwd())\n",
    "\n",
    "# with open('vis_driven.pickle', 'wb') as f:\n",
    "#     pickle.dump(vis_driven_re, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97097211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i1323_200720_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(103, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 393.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1323_200720_003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# # session_mode = 'multi session' # then irun must be appended to dir_sub !\n",
    "\n",
    "# ## set up logging\n",
    "# plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "# logging.basicConfig(filename='C:/Users/ll357/Documents/inter/data/vis_driven.log', level=logging.DEBUG)\n",
    "# logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "# logging.info(str(datetime.now()))\n",
    "\n",
    "# for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "#     # clear_output(wait=True)\n",
    "#     logging.info(f'set {i+1} of {nset}')\n",
    "#     mouse = meta.iloc[i].mouse.astype(str)\n",
    "#     date = meta.iloc[i].date.astype(str)\n",
    "#     area = meta.iloc[i].area\n",
    "#     irun = '00' + meta.iloc[i].num.astype(int).astype(str)\n",
    "#     logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "#     ## check if resp_base_trialwise exists\n",
    "#     ## load data\n",
    "#     logging.info('waiting for mat')\n",
    "#     print('waiting for mat')\n",
    "#     while True:\n",
    "#         try:\n",
    "#             dir_sub = area + '_i' + mouse + '_' + date\n",
    "#             if session_mode == 'single session':\n",
    "#                 dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "#             print(dir_sub)\n",
    "#             try: # manual seg data has no suffix '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             except: # cellpose seg data has suffix '_cellpose'\n",
    "#                 dir_sub += '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             logging.info('mat loaded')\n",
    "#             break\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             clear_output(wait=True)\n",
    "#             continue\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#         isi_mode = 'only one isi'\n",
    "#         print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#         dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#         dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#         isi_mode = 'grat_8ori_3isi'\n",
    "#         print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#         dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#         dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#         print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "#     ## stats\n",
    "#     if isi_mode == 'only one isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_ad_trial.shape[0]\n",
    "#         nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base_trial[icell, istim]\n",
    "#                 stim_cell = dfof_ad_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     elif isi_mode == 'grat_8ori_3isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_tg_trial.shape[0]\n",
    "#         nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base2_trial[icell, istim]\n",
    "#                 stim_cell = dfof_tg_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "#     p_sig = 0.05\n",
    "#     vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "#     logging.info(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#         proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "#     # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "#     img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "#     logging.info(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#         proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#         1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "#     t = np.sum(img_driven, axis=1)\n",
    "#     logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "#     ## save\n",
    "#     vis_driven_re = {}\n",
    "#     vis_driven_re['p_anova'] = p_anova\n",
    "#     vis_driven_re['p_kruskal'] = p_kruskal\n",
    "#     vis_driven_re['p_ttest'] = p_ttest\n",
    "#     vis_driven_re['evoked'] = evoked\n",
    "#     vis_driven_re['p_sig'] = p_sig\n",
    "#     vis_driven_re['vis_driven'] = vis_driven\n",
    "#     vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "#     os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "#     print(os.getcwd())\n",
    "#     with open('vis_driven.pickle', 'wb') as f:\n",
    "#         pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "#     # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "654a1d97444558a991daa59b50de40303e0e66ccc3f29b4958db12481daba1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
