{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b650af2",
   "metadata": {},
   "source": [
    "# cell filter\n",
    "visually responsive & image driven "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2a5d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1    12\n",
      "Name: area, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>depth</th>\n",
       "      <th>num</th>\n",
       "      <th>cellpose_seg</th>\n",
       "      <th>manual_seg</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>gcamp</th>\n",
       "      <th>AWS</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>674</td>\n",
       "      <td>170324</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TC and input already concat-ed 002-003. see in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>689</td>\n",
       "      <td>170323</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>696</td>\n",
       "      <td>170323</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>684</td>\n",
       "      <td>170327</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711</td>\n",
       "      <td>170503</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>712</td>\n",
       "      <td>170503</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>574</td>\n",
       "      <td>170510</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>720</td>\n",
       "      <td>170808</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>738</td>\n",
       "      <td>170810</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>739</td>\n",
       "      <td>170811</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>745</td>\n",
       "      <td>170816</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>746</td>\n",
       "      <td>170826</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mouse    date area  depth      num  cellpose_seg manual_seg  \\\n",
       "0     674  170324   V1    NaN  002-003           NaN       True   \n",
       "1     689  170323   V1    NaN  002-003           NaN       True   \n",
       "2     696  170323   V1    NaN  002-003           NaN       True   \n",
       "3     684  170327   V1    NaN  002-003           NaN       True   \n",
       "4     711  170503   V1    NaN  002-003           NaN       True   \n",
       "5     712  170503   V1    NaN  002-003           NaN       True   \n",
       "6     574  170510   V1    NaN  002-003           NaN       True   \n",
       "7     720  170808   V1    NaN  002-003           NaN       True   \n",
       "8     738  170810   V1    NaN  002-003           NaN       True   \n",
       "9     739  170811   V1    NaN  002-003           NaN       True   \n",
       "10    745  170816   V1    NaN  002-003           NaN       True   \n",
       "11    746  170826   V1    NaN  002-003           NaN       True   \n",
       "\n",
       "                    paradigm gcamp  AWS  \\\n",
       "0   grating_lindsey_miaomiao    6f  NaN   \n",
       "1   grating_lindsey_miaomiao    6f  NaN   \n",
       "2   grating_lindsey_miaomiao    6s  NaN   \n",
       "3   grating_lindsey_miaomiao    6f  NaN   \n",
       "4   grating_lindsey_miaomiao    6s  NaN   \n",
       "5   grating_lindsey_miaomiao    6s  NaN   \n",
       "6   grating_lindsey_miaomiao    6s  NaN   \n",
       "7   grating_lindsey_miaomiao    6s  NaN   \n",
       "8   grating_lindsey_miaomiao    6f  NaN   \n",
       "9   grating_lindsey_miaomiao    6f  NaN   \n",
       "10  grating_lindsey_miaomiao    6f  NaN   \n",
       "11  grating_lindsey_miaomiao    6f  NaN   \n",
       "\n",
       "                                                 note  \n",
       "0   TC and input already concat-ed 002-003. see in...  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_inter = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter/'.replace('\\\\', '/')\n",
    "dir_file = dir_inter + 'adp_dataset_master.xlsx'\n",
    "data_info = pd.read_excel(dir_file)\n",
    "data_info.head()\n",
    "\n",
    "meta = data_info[(data_info.paradigm == 'grating_lindsey_miaomiao') \n",
    "                #  & (data_info.area == 'LM')\n",
    "                #  & (data_info.gcamp == '6s') # avoid mixing in gcamp8f\n",
    "                #  & ((data_info.cellpose_seg == True) | (data_info.manual_seg == True)) # ensure segmentation\n",
    "                 ]\n",
    "\n",
    "meta = meta.reset_index(drop=True)\n",
    "nset = meta.shape[0]\n",
    "print(meta.area.value_counts())\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2deab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i674_170324_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(73, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 611.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 cells are image driven - with overlap between images, \n",
      "        proportion 0.1 out of 584 cell-stim combos. \n",
      "        1-N image evokes resp from [10  3  7  7 11  4  9 10] cells\n",
      "41 cells are visually driven, \n",
      "        proportion 0.56 out of 73 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i674_170324_002-003\n",
      "waiting for mat\n",
      "V1_i689_170323_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(19, 8, 3) (14, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 558.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 152 cell-stim combos. \n",
      "        1-N image evokes resp from [3 2 3 4 1 1 0 4] cells\n",
      "9 cells are visually driven, \n",
      "        proportion 0.47 out of 19 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i689_170323_002-003\n",
      "waiting for mat\n",
      "V1_i696_170323_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(73, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 536.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 cells are image driven - with overlap between images, \n",
      "        proportion 0.2 out of 584 cell-stim combos. \n",
      "        1-N image evokes resp from [ 0 19 11 22 19 13 17 15] cells\n",
      "55 cells are visually driven, \n",
      "        proportion 0.75 out of 73 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i696_170323_002-003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i684_170327_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(31, 8, 3) (14, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 563.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 cells are image driven - with overlap between images, \n",
      "        proportion 0.26 out of 248 cell-stim combos. \n",
      "        1-N image evokes resp from [13  6  6 12  9  7  6  6] cells\n",
      "29 cells are visually driven, \n",
      "        proportion 0.94 out of 31 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i684_170327_002-003\n",
      "waiting for mat\n",
      "V1_i711_170503_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(33, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 508.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 cells are image driven - with overlap between images, \n",
      "        proportion 0.18 out of 264 cell-stim combos. \n",
      "        1-N image evokes resp from [6 8 6 5 6 5 6 5] cells\n",
      "24 cells are visually driven, \n",
      "        proportion 0.73 out of 33 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i711_170503_002-003\n",
      "waiting for mat\n",
      "V1_i712_170503_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(43, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 613.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 cells are image driven - with overlap between images, \n",
      "        proportion 0.24 out of 344 cell-stim combos. \n",
      "        1-N image evokes resp from [13 11  9  6 11  8  9 15] cells\n",
      "34 cells are visually driven, \n",
      "        proportion 0.79 out of 43 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i712_170503_002-003\n",
      "waiting for mat\n",
      "V1_i574_170510_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(94, 8, 3) (14, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 570.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 cells are image driven - with overlap between images, \n",
      "        proportion 0.27 out of 752 cell-stim combos. \n",
      "        1-N image evokes resp from [29 25 28 18 19 31 22 32] cells\n",
      "87 cells are visually driven, \n",
      "        proportion 0.93 out of 94 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i574_170510_002-003\n",
      "waiting for mat\n",
      "V1_i720_170808_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(55, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 567.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 cells are image driven - with overlap between images, \n",
      "        proportion 0.23 out of 440 cell-stim combos. \n",
      "        1-N image evokes resp from [ 8  8 14 17 12 20 14 10] cells\n",
      "51 cells are visually driven, \n",
      "        proportion 0.93 out of 55 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i720_170808_002-003\n",
      "waiting for mat\n",
      "V1_i738_170810_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(16, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 572.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 cells are image driven - with overlap between images, \n",
      "        proportion 0.33 out of 128 cell-stim combos. \n",
      "        1-N image evokes resp from [8 5 0 5 2 9 7 6] cells\n",
      "15 cells are visually driven, \n",
      "        proportion 0.94 out of 16 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i738_170810_002-003\n",
      "waiting for mat\n",
      "V1_i739_170811_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(35, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 659.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 cells are image driven - with overlap between images, \n",
      "        proportion 0.17 out of 280 cell-stim combos. \n",
      "        1-N image evokes resp from [ 3  2  6  7  7  8  5 10] cells\n",
      "32 cells are visually driven, \n",
      "        proportion 0.91 out of 35 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i739_170811_002-003\n",
      "waiting for mat\n",
      "V1_i745_170816_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(66, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 580.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 cells are image driven - with overlap between images, \n",
      "        proportion 0.17 out of 528 cell-stim combos. \n",
      "        1-N image evokes resp from [13 12 12  0 15 12 16 10] cells\n",
      "60 cells are visually driven, \n",
      "        proportion 0.91 out of 66 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i745_170816_002-003\n",
      "waiting for mat\n",
      "V1_i746_170826_002-003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(49, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 571.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 cells are image driven - with overlap between images, \n",
      "        proportion 0.18 out of 392 cell-stim combos. \n",
      "        1-N image evokes resp from [ 6  9 13  0 13  9  6 13] cells\n",
      "45 cells are visually driven, \n",
      "        proportion 0.92 out of 49 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i746_170826_002-003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# session_mode = 'multi session' # then irun must be appended to dir_sub !\n",
    "\n",
    "## set up logging\n",
    "plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "logging.basicConfig(filename='C:/Users/ll357/Documents/inter/data/vis_driven.log', level=logging.DEBUG)\n",
    "logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "logging.info(str(datetime.now()))\n",
    "\n",
    "for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "    # clear_output(wait=True)\n",
    "    logging.info(f'set {i+1} of {nset}')\n",
    "    mouse = meta.iloc[i].mouse.astype(str)\n",
    "    date = meta.iloc[i].date.astype(str)\n",
    "    area = meta.iloc[i].area\n",
    "    irun = meta.iloc[i].num # already a string due to concat lindsey's grating 8ori data\n",
    "    logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "    ## check if resp_base_trialwise exists\n",
    "    ## load data\n",
    "    logging.info('waiting for mat')\n",
    "    print('waiting for mat')\n",
    "    while True:\n",
    "        try:\n",
    "            dir_sub = area + '_i' + mouse + '_' + date\n",
    "            if session_mode == 'single session':\n",
    "                dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "            print(dir_sub)\n",
    "            try: # manual seg data has no suffix '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            except: # cellpose seg data has suffix '_cellpose'\n",
    "                dir_sub += '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            logging.info('mat loaded')\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(60)\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "        isi_mode = 'only one isi'\n",
    "        print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "        dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "        dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "        isi_mode = 'grat_8ori_3isi'\n",
    "        print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "        dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "        dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "        print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "    ## stats\n",
    "    if isi_mode == 'only one isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_ad_trial.shape[0]\n",
    "        nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base_trial[icell, istim]\n",
    "                stim_cell = dfof_ad_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "    elif isi_mode == 'grat_8ori_3isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_tg_trial.shape[0]\n",
    "        nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "        # according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base2_trial[icell, istim]\n",
    "                stim_cell = dfof_tg_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "\n",
    "    # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "    p_sig = 0.05\n",
    "    evoked_thresh = 0.05\n",
    "    img_driven = (p_ttest < p_sig) & (evoked > evoked_thresh)\n",
    "    img_driven_msg = f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "        proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "        1-N image evokes resp from {np.sum(img_driven, axis=0)} cells'\n",
    "    logging.info(img_driven_msg)\n",
    "    print(img_driven_msg)\n",
    "\n",
    "    t = np.sum(img_driven, axis=1)\n",
    "    logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "    # visually driven cells: NOTE changed to: driven by any image (pass t-test to any stim2, but with bonferroni correction) AND amp threshold. \n",
    "    loosen_sig = 6\n",
    "    p_bonferroni_corrected = loosen_sig * p_sig / nstim # number of possible stim2\n",
    "    vis_driven = ((np.sum(p_ttest < p_bonferroni_corrected, axis=1) > 0) # any stim2 passes t-test\n",
    "                & (np.sum(evoked > evoked_thresh, axis=1) > 0) # any stim2 evokes resp > thresh\n",
    "                )\n",
    "    vis_driven_msg = f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells'\n",
    "    logging.info(vis_driven_msg)\n",
    "    print(vis_driven_msg)\n",
    "\n",
    "    # break\n",
    "\n",
    "    ## save\n",
    "    vis_driven_re = {}\n",
    "    # vis_driven_re['p_anova'] = p_anova\n",
    "    # vis_driven_re['p_kruskal'] = p_kruskal\n",
    "    vis_driven_re['p_ttest'] = p_ttest\n",
    "    vis_driven_re['evoked'] = evoked\n",
    "    vis_driven_re['p_sig'] = p_sig\n",
    "    vis_driven_re['p_bonferroni_corrected'] = p_bonferroni_corrected\n",
    "    vis_driven_re['vis_driven'] = vis_driven\n",
    "    vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "    os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "    print(os.getcwd())\n",
    "    with open('vis_driven_ttest_bonferroni.pickle', 'wb') as f:\n",
    "        pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcf66db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1337_210120_003_cellpose/'.replace('\\\\', '/')\n",
    "with open(pickle_dir+'vis_driven_ttest_bonferroni.pickle', 'rb') as f:\n",
    "    vis_driven_re = pickle.load(f)\n",
    "vis_driven_re['vis_driven'].shape\n",
    "\n",
    "import scipy.io as sio\n",
    "os.chdir(r'C:\\Users\\ll357\\Documents\\inter\\results\\tuning curve bias san check'.replace('\\\\', '/'))\n",
    "sio.savemat('vis_driven_ttest_bonferroni.mat', vis_driven_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4080456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64 cells are visually driven, \\n        proportion 0.62 out of 103 cells'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97097211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i1323_200720_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(103, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 393.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1323_200720_003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# # session_mode = 'multi session' # then irun must be appended to dir_sub !\n",
    "\n",
    "# ## set up logging\n",
    "# plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "# logging.basicConfig(filename='C:/Users/ll357/Documents/inter/data/vis_driven.log', level=logging.DEBUG)\n",
    "# logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "# logging.info(str(datetime.now()))\n",
    "\n",
    "# for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "#     # clear_output(wait=True)\n",
    "#     logging.info(f'set {i+1} of {nset}')\n",
    "#     mouse = meta.iloc[i].mouse.astype(str)\n",
    "#     date = meta.iloc[i].date.astype(str)\n",
    "#     area = meta.iloc[i].area\n",
    "#     irun = '00' + meta.iloc[i].num.astype(int).astype(str)\n",
    "#     logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "#     ## check if resp_base_trialwise exists\n",
    "#     ## load data\n",
    "#     logging.info('waiting for mat')\n",
    "#     print('waiting for mat')\n",
    "#     while True:\n",
    "#         try:\n",
    "#             dir_sub = area + '_i' + mouse + '_' + date\n",
    "#             if session_mode == 'single session':\n",
    "#                 dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "#             print(dir_sub)\n",
    "#             try: # manual seg data has no suffix '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             except: # cellpose seg data has suffix '_cellpose'\n",
    "#                 dir_sub += '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             logging.info('mat loaded')\n",
    "#             break\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             clear_output(wait=True)\n",
    "#             continue\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#         isi_mode = 'only one isi'\n",
    "#         print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#         dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#         dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#         isi_mode = 'grat_8ori_3isi'\n",
    "#         print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#         dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#         dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#         print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "#     ## stats\n",
    "#     if isi_mode == 'only one isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_ad_trial.shape[0]\n",
    "#         nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base_trial[icell, istim]\n",
    "#                 stim_cell = dfof_ad_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     elif isi_mode == 'grat_8ori_3isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_tg_trial.shape[0]\n",
    "#         nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base2_trial[icell, istim]\n",
    "#                 stim_cell = dfof_tg_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "#     p_sig = 0.05\n",
    "#     vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "#     logging.info(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#         proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "#     # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "#     img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "#     logging.info(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#         proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#         1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "#     t = np.sum(img_driven, axis=1)\n",
    "#     logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "#     ## save\n",
    "#     vis_driven_re = {}\n",
    "#     vis_driven_re['p_anova'] = p_anova\n",
    "#     vis_driven_re['p_kruskal'] = p_kruskal\n",
    "#     vis_driven_re['p_ttest'] = p_ttest\n",
    "#     vis_driven_re['evoked'] = evoked\n",
    "#     vis_driven_re['p_sig'] = p_sig\n",
    "#     vis_driven_re['vis_driven'] = vis_driven\n",
    "#     vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "#     os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "#     print(os.getcwd())\n",
    "#     with open('vis_driven.pickle', 'wb') as f:\n",
    "#         pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51fa8fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(base_cell_anova).flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a418769e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (18,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_cell_anova.__len__(), stim_cell_anova[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a103ca42",
   "metadata": {},
   "source": [
    "# depre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6659cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323 200721\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n"
     ]
    }
   ],
   "source": [
    "# # meta = pd.read_excel(mat_inter_path + 'adp_dataset_master.xlsx')\n",
    "\n",
    "# # date_str = str(200721)\n",
    "# # mouse_str = meta.loc[meta['date'] == int(date_str), 'mouse'].values#[0]\n",
    "# # area_str = meta.loc[meta['date'] == int(date_str), 'area'].values[0]\n",
    "# # if len(mouse_str) > 1:\n",
    "# #     print('duplicate dates with maybe different mouse. select which mouse?')\n",
    "# # else:\n",
    "# #     mouse_str = str(mouse_str[0])\n",
    "# # print(mouse_str, date_str)\n",
    "\n",
    "# try:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + '_cellpose'\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# except:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + ''\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#     mode = 'only one isi'\n",
    "#     print(f'mode is {mode} (only one isi, grat_SF or bunny)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#     dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#     dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#     mode = 'grat_8ori_3isi'\n",
    "#     print(f'mode is {mode} (grating with 8 orientations and 3 ISI)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#     dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#     dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#     print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b51367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 345.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# if mode == 'only one isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_ad_trial.shape[0]\n",
    "#     nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base_trial[icell, istim]\n",
    "#             stim_cell = dfof_ad_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "# elif mode == 'grat_8ori_3isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_tg_trial.shape[0]\n",
    "#     nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base2_trial[icell, istim]\n",
    "#             stim_cell = dfof_tg_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395531aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 cells are visually driven, \n",
      "    proportion 0.67 out of 39 cells\n",
      "29 cells are image driven - with overlap between images, \n",
      "    proportion 0.09 out of 312 cell-stim combos. \n",
      "    1-N image evokes resp from [4 2 6 1 3 2 5 6] cells\n",
      "img driven cells are driven by [1 2 2 1 2 1 1 1 2 1 2 1 4 1 1 1 1 3 1] images\n"
     ]
    }
   ],
   "source": [
    "# # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "# p_sig = 0.05\n",
    "# vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "# print(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#     proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "# # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "# img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "# print(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#     proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#     1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "# t = np.sum(img_driven, axis=1)\n",
    "# print(f'img driven cells are driven by {t[t>0]} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabf9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\duhs-user-nc1.dhe.duke.edu\\dusom_glickfeldlab\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721\n"
     ]
    }
   ],
   "source": [
    "# vis_driven_re = {}\n",
    "# vis_driven_re['p_anova'] = p_anova\n",
    "# vis_driven_re['p_kruskal'] = p_kruskal\n",
    "# vis_driven_re['p_ttest'] = p_ttest\n",
    "# vis_driven_re['evoked'] = evoked\n",
    "# vis_driven_re['p_sig'] = p_sig\n",
    "# vis_driven_re['vis_driven'] = vis_driven\n",
    "# vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "# os.chdir(os.path.join(mat_inter_path, dir_sub))\n",
    "# print(os.getcwd())\n",
    "\n",
    "# with open('vis_driven.pickle', 'wb') as f:\n",
    "#     pickle.dump(vis_driven_re, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "654a1d97444558a991daa59b50de40303e0e66ccc3f29b4958db12481daba1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
