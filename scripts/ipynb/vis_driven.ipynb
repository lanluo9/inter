{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b650af2",
   "metadata": {},
   "source": [
    "# cell filter\n",
    "visually responsive & image driven "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f8eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>depth</th>\n",
       "      <th>num</th>\n",
       "      <th>cellpose_seg</th>\n",
       "      <th>manual_seg</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>gcamp</th>\n",
       "      <th>AWS</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>745</td>\n",
       "      <td>170816</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>746</td>\n",
       "      <td>170826</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mouse    date area  depth      num  cellpose_seg manual_seg  \\\n",
       "163    745  170816   V1    NaN  002-003           NaN       True   \n",
       "164    746  170826   V1    NaN  002-003           NaN       True   \n",
       "165   1380  230622   V1    NaN      002           NaN        NaN   \n",
       "166   1380  230622   V1    NaN      003           NaN        NaN   \n",
       "167   1380  230622   V1    NaN      004           NaN        NaN   \n",
       "\n",
       "                     paradigm gcamp  AWS note  \n",
       "163  grating_lindsey_miaomiao    6f  NaN  NaN  \n",
       "164  grating_lindsey_miaomiao    6f  NaN  NaN  \n",
       "165    grating_8ori_multisess    6s  NaN  NaN  \n",
       "166    grating_8ori_multisess    6s  NaN  NaN  \n",
       "167    grating_8ori_multisess    6s  NaN  NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_inter = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter/'.replace('\\\\', '/')\n",
    "dir_file = dir_inter + 'adp_dataset_master.xlsx'\n",
    "data_info = pd.read_excel(dir_file)\n",
    "data_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e2a5d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM    22\n",
      "LI    18\n",
      "V1     6\n",
      "Name: area, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>depth</th>\n",
       "      <th>num</th>\n",
       "      <th>cellpose_seg</th>\n",
       "      <th>manual_seg</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>gcamp</th>\n",
       "      <th>AWS</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323</td>\n",
       "      <td>200720</td>\n",
       "      <td>V1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1323</td>\n",
       "      <td>200721</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1323</td>\n",
       "      <td>200723</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1324</td>\n",
       "      <td>200728</td>\n",
       "      <td>V1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1324</td>\n",
       "      <td>200729</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1322</td>\n",
       "      <td>200803</td>\n",
       "      <td>V1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1322</td>\n",
       "      <td>200804</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1322</td>\n",
       "      <td>200806</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1328</td>\n",
       "      <td>201015</td>\n",
       "      <td>V1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1328</td>\n",
       "      <td>201119</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1328</td>\n",
       "      <td>201127</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1328</td>\n",
       "      <td>201202</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1328</td>\n",
       "      <td>201202</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1329</td>\n",
       "      <td>201209</td>\n",
       "      <td>V1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1329</td>\n",
       "      <td>201217</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1329</td>\n",
       "      <td>201217</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1329</td>\n",
       "      <td>210113</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1329</td>\n",
       "      <td>210113</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1337</td>\n",
       "      <td>210120</td>\n",
       "      <td>V1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1337</td>\n",
       "      <td>210127</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1337</td>\n",
       "      <td>210127</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1337</td>\n",
       "      <td>210203</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1337</td>\n",
       "      <td>210203</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1338</td>\n",
       "      <td>210325</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1338</td>\n",
       "      <td>210805</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1339</td>\n",
       "      <td>210930</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1339</td>\n",
       "      <td>210930</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1350</td>\n",
       "      <td>211020</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1350</td>\n",
       "      <td>211020</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1350</td>\n",
       "      <td>211028</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1350</td>\n",
       "      <td>211028</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1351</td>\n",
       "      <td>220228</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1351</td>\n",
       "      <td>220228</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1380</td>\n",
       "      <td>230110</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1380</td>\n",
       "      <td>230110</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1380</td>\n",
       "      <td>230221</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1380</td>\n",
       "      <td>230221</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TC not pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1373</td>\n",
       "      <td>230228</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1373</td>\n",
       "      <td>230228</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1373</td>\n",
       "      <td>230302</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1373</td>\n",
       "      <td>230302</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1381</td>\n",
       "      <td>230307</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1381</td>\n",
       "      <td>230307</td>\n",
       "      <td>LM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1381</td>\n",
       "      <td>230307</td>\n",
       "      <td>LM</td>\n",
       "      <td>150.0</td>\n",
       "      <td>004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1381</td>\n",
       "      <td>230309</td>\n",
       "      <td>LI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1381</td>\n",
       "      <td>230309</td>\n",
       "      <td>LI</td>\n",
       "      <td>150.0</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>grating</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>terrible find_ca_latency_ca_window.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mouse    date area  depth  num  cellpose_seg manual_seg paradigm gcamp  \\\n",
       "0    1323  200720   V1  200.0  003           NaN       True  grating    6s   \n",
       "1    1323  200721   LM  200.0  002           NaN       True  grating    6s   \n",
       "2    1323  200723   LI  200.0  003           NaN       True  grating    6s   \n",
       "3    1324  200728   V1  200.0  003           NaN       True  grating    6s   \n",
       "4    1324  200729   LM  200.0  003           NaN       True  grating    6s   \n",
       "5    1322  200803   V1  200.0  002           NaN       True  grating    6s   \n",
       "6    1322  200804   LM  200.0  003           NaN       True  grating    6s   \n",
       "7    1322  200806   LI  200.0  003           NaN       True  grating    6s   \n",
       "8    1328  201015   V1  200.0  004           NaN       True  grating    6s   \n",
       "9    1328  201119   LM  200.0  003           NaN       True  grating    6s   \n",
       "10   1328  201127   LM  200.0  002           NaN       True  grating    6s   \n",
       "11   1328  201202   LI  200.0  003           NaN       True  grating    6s   \n",
       "12   1328  201202   LI  150.0  004           NaN       True  grating    6s   \n",
       "13   1329  201209   V1  200.0  002           NaN       True  grating    6s   \n",
       "14   1329  201217   LM  200.0  002           1.0        NaN  grating    6s   \n",
       "15   1329  201217   LM  150.0  004           1.0        NaN  grating    6s   \n",
       "16   1329  210113   LI  200.0  004           NaN       True  grating    6s   \n",
       "17   1329  210113   LI  150.0  006           NaN       True  grating    6s   \n",
       "18   1337  210120   V1  150.0  003           1.0        NaN  grating    6s   \n",
       "19   1337  210127   LM  200.0  002           1.0        NaN  grating    6s   \n",
       "20   1337  210127   LM  150.0  003           1.0        NaN  grating    6s   \n",
       "21   1337  210203   LI  200.0  003           NaN       True  grating    6s   \n",
       "22   1337  210203   LI  150.0  004           NaN       True  grating    6s   \n",
       "23   1338  210325   LM  200.0  002           1.0        NaN  grating    6s   \n",
       "24   1338  210805   LM  150.0  002           1.0        NaN  grating    6s   \n",
       "25   1339  210930   LI  200.0  002           NaN       True  grating    6s   \n",
       "26   1339  210930   LI  150.0  003           NaN       True  grating    6s   \n",
       "27   1350  211020   LM  200.0  002           1.0        NaN  grating    6s   \n",
       "28   1350  211020   LM  150.0  003           1.0        NaN  grating    6s   \n",
       "29   1350  211028   LI  200.0  002           NaN       True  grating    6s   \n",
       "30   1350  211028   LI  150.0  003           NaN       True  grating    6s   \n",
       "31   1351  220228   LM  200.0  002           1.0        NaN  grating    6s   \n",
       "32   1351  220228   LM  150.0  003           1.0        NaN  grating    6s   \n",
       "33   1380  230110   LI  200.0  002           1.0       True  grating    6s   \n",
       "34   1380  230110   LI  150.0  003           1.0       True  grating    6s   \n",
       "35   1380  230221   LM  200.0  002           1.0        NaN  grating    6s   \n",
       "36   1380  230221   LM  150.0  003           1.0        NaN  grating    6s   \n",
       "37   1373  230228   LI  200.0  002           1.0        NaN  grating    6s   \n",
       "38   1373  230228   LI  150.0  003           1.0        NaN  grating    6s   \n",
       "39   1373  230302   LM  200.0  003           1.0        NaN  grating    6s   \n",
       "40   1373  230302   LM  150.0  004           1.0        NaN  grating    6s   \n",
       "41   1381  230307   LM  200.0  002           1.0        NaN  grating    6s   \n",
       "42   1381  230307   LM  200.0  003           1.0        NaN  grating    6s   \n",
       "43   1381  230307   LM  150.0  004           1.0        NaN  grating    6s   \n",
       "44   1381  230309   LI  200.0  002           1.0       True  grating    6s   \n",
       "45   1381  230309   LI  150.0  003           1.0       True  grating    6s   \n",
       "\n",
       "    AWS                                    note  \n",
       "0   1.0                                     NaN  \n",
       "1   1.0                                     NaN  \n",
       "2   1.0                                     NaN  \n",
       "3   NaN                                     NaN  \n",
       "4   1.0                                     NaN  \n",
       "5   NaN                                     NaN  \n",
       "6   1.0                                     NaN  \n",
       "7   1.0                                     NaN  \n",
       "8   1.0                                     NaN  \n",
       "9   1.0                                     NaN  \n",
       "10  1.0                                     NaN  \n",
       "11  1.0  terrible find_ca_latency_ca_window.jpg  \n",
       "12  1.0  terrible find_ca_latency_ca_window.jpg  \n",
       "13  NaN                                     NaN  \n",
       "14  NaN                                     NaN  \n",
       "15  NaN                                     NaN  \n",
       "16  NaN                                     NaN  \n",
       "17  NaN  terrible find_ca_latency_ca_window.jpg  \n",
       "18  NaN                                     NaN  \n",
       "19  NaN                                     NaN  \n",
       "20  NaN                                     NaN  \n",
       "21  NaN                                     NaN  \n",
       "22  NaN                                     NaN  \n",
       "23  NaN                                     NaN  \n",
       "24  NaN                                     NaN  \n",
       "25  NaN  terrible find_ca_latency_ca_window.jpg  \n",
       "26  NaN  terrible find_ca_latency_ca_window.jpg  \n",
       "27  NaN                                     NaN  \n",
       "28  NaN                                     NaN  \n",
       "29  NaN  terrible find_ca_latency_ca_window.jpg  \n",
       "30  NaN  terrible find_ca_latency_ca_window.jpg  \n",
       "31  NaN                                     NaN  \n",
       "32  NaN                                     NaN  \n",
       "33  NaN                                     NaN  \n",
       "34  NaN  terrible find_ca_latency_ca_window.jpg  \n",
       "35  NaN                                     NaN  \n",
       "36  NaN                           TC not pretty  \n",
       "37  NaN                                     NaN  \n",
       "38  NaN                                     NaN  \n",
       "39  NaN                                     NaN  \n",
       "40  NaN                                     NaN  \n",
       "41  NaN                                     NaN  \n",
       "42  NaN                                     NaN  \n",
       "43  NaN                                     NaN  \n",
       "44  NaN  terrible find_ca_latency_ca_window.jpg  \n",
       "45  NaN  terrible find_ca_latency_ca_window.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = data_info[(data_info.paradigm == 'grating') # grating_8ori_multisess\n",
    "                #  & (data_info.area == 'LM')\n",
    "                 & (data_info.gcamp == '6s') # avoid mixing in gcamp8f\n",
    "                 & ((data_info.cellpose_seg == True) | (data_info.manual_seg == True)) # ensure segmentation\n",
    "                 ]\n",
    "\n",
    "meta = meta.reset_index(drop=True)\n",
    "nset = meta.shape[0]\n",
    "print(meta.area.value_counts())\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa2deab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i1323_200720_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(103, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 195.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 cells are image driven - with overlap between images, \n",
      "        proportion 0.08 out of 824 cell-stim combos. \n",
      "        1-N image evokes resp from [ 5  4  8 12 10  6 12  8] cells\n",
      "26 cells are visually driven, \n",
      "        proportion 0.25 out of 103 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1323_200720_003\n",
      "waiting for mat\n",
      "LM_i1323_200721_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 183.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 cells are image driven - with overlap between images, \n",
      "        proportion 0.1 out of 312 cell-stim combos. \n",
      "        1-N image evokes resp from [5 1 6 2 3 2 6 6] cells\n",
      "21 cells are visually driven, \n",
      "        proportion 0.54 out of 39 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721_002\n",
      "waiting for mat\n",
      "LI_i1323_200723_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(33, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 194.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 cells are image driven - with overlap between images, \n",
      "        proportion 0.16 out of 264 cell-stim combos. \n",
      "        1-N image evokes resp from [ 4 11  5  6  3  0  5  8] cells\n",
      "14 cells are visually driven, \n",
      "        proportion 0.42 out of 33 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1323_200723_003\n",
      "waiting for mat\n",
      "V1_i1324_200728_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(93, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:00<00:00, 192.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 cells are image driven - with overlap between images, \n",
      "        proportion 0.19 out of 744 cell-stim combos. \n",
      "        1-N image evokes resp from [11 11 22 12 20 19 25 18] cells\n",
      "66 cells are visually driven, \n",
      "        proportion 0.71 out of 93 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1324_200728_003\n",
      "waiting for mat\n",
      "LM_i1324_200729_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(52, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 194.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 416 cell-stim combos. \n",
      "        1-N image evokes resp from [2 0 1 1 2 2 1 1] cells\n",
      "3 cells are visually driven, \n",
      "        proportion 0.06 out of 52 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1324_200729_003\n",
      "waiting for mat\n",
      "V1_i1322_200803_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(97, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 193.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 cells are image driven - with overlap between images, \n",
      "        proportion 0.18 out of 776 cell-stim combos. \n",
      "        1-N image evokes resp from [22 15 19 16 11 15 15 26] cells\n",
      "68 cells are visually driven, \n",
      "        proportion 0.7 out of 97 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1322_200803_002\n",
      "waiting for mat\n",
      "LM_i1322_200804_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(69, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:00<00:00, 195.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 cells are image driven - with overlap between images, \n",
      "        proportion 0.21 out of 552 cell-stim combos. \n",
      "        1-N image evokes resp from [16 15 13 17 17 16 13  8] cells\n",
      "38 cells are visually driven, \n",
      "        proportion 0.55 out of 69 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1322_200804_003\n",
      "waiting for mat\n",
      "LI_i1322_200806_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(53, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 196.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 cells are image driven - with overlap between images, \n",
      "        proportion 0.13 out of 424 cell-stim combos. \n",
      "        1-N image evokes resp from [ 2  8  7  4 13 16  1  5] cells\n",
      "20 cells are visually driven, \n",
      "        proportion 0.38 out of 53 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1322_200806_003\n",
      "waiting for mat\n",
      "V1_i1328_201015_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(82, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 194.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 656 cell-stim combos. \n",
      "        1-N image evokes resp from [ 8 11  9 12 12  8 10 10] cells\n",
      "46 cells are visually driven, \n",
      "        proportion 0.56 out of 82 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1328_201015_004\n",
      "waiting for mat\n",
      "LM_i1328_201119_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(71, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:00<00:00, 194.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 cells are image driven - with overlap between images, \n",
      "        proportion 0.04 out of 568 cell-stim combos. \n",
      "        1-N image evokes resp from [1 8 2 2 1 0 4 3] cells\n",
      "7 cells are visually driven, \n",
      "        proportion 0.1 out of 71 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1328_201119_003\n",
      "waiting for mat\n",
      "LM_i1328_201127_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(40, 8, 4) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 193.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 cells are image driven - with overlap between images, \n",
      "        proportion 0.06 out of 320 cell-stim combos. \n",
      "        1-N image evokes resp from [2 3 4 2 2 2 1 3] cells\n",
      "17 cells are visually driven, \n",
      "        proportion 0.42 out of 40 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1328_201127_002\n",
      "waiting for mat\n",
      "LI_i1328_201202_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(9, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 191.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cells are image driven - with overlap between images, \n",
      "        proportion 0.01 out of 72 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 1 0 0 0 0 0] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.22 out of 9 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1328_201202_003\n",
      "waiting for mat\n",
      "LI_i1328_201202_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(29, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 177.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 cells are image driven - with overlap between images, \n",
      "        proportion 0.04 out of 232 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 2 1 1 1 2 2] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.07 out of 29 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1328_201202_004\n",
      "waiting for mat\n",
      "V1_i1329_201209_002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(146, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:00<00:00, 195.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 cells are image driven - with overlap between images, \n",
      "        proportion 0.09 out of 1168 cell-stim combos. \n",
      "        1-N image evokes resp from [16 15 11 17  6 12 11 20] cells\n",
      "33 cells are visually driven, \n",
      "        proportion 0.23 out of 146 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1329_201209_002\n",
      "waiting for mat\n",
      "LM_i1329_201217_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(107, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 198.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 cells are image driven - with overlap between images, \n",
      "        proportion 0.13 out of 856 cell-stim combos. \n",
      "        1-N image evokes resp from [14 12 14 14 16 13 15 17] cells\n",
      "43 cells are visually driven, \n",
      "        proportion 0.4 out of 107 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1329_201217_002_cellpose\n",
      "waiting for mat\n",
      "LM_i1329_201217_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(90, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 195.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 720 cell-stim combos. \n",
      "        1-N image evokes resp from [13 11  9  8  9  5  9 12] cells\n",
      "21 cells are visually driven, \n",
      "        proportion 0.23 out of 90 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1329_201217_004_cellpose\n",
      "waiting for mat\n",
      "LI_i1329_210113_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(22, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 198.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 176 cell-stim combos. \n",
      "        1-N image evokes resp from [0 1 1 0 1 0 2 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 22 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1329_210113_004_cellpose\n",
      "waiting for mat\n",
      "LI_i1329_210113_006\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(23, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 193.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cells are image driven - with overlap between images, \n",
      "        proportion 0.01 out of 184 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 1 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 23 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1329_210113_006_cellpose\n",
      "waiting for mat\n",
      "V1_i1337_210120_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 194.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 cells are image driven - with overlap between images, \n",
      "        proportion 0.24 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [14 18  8 15 13 12 22 19] cells\n",
      "45 cells are visually driven, \n",
      "        proportion 0.73 out of 62 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1337_210120_003_cellpose\n",
      "waiting for mat\n",
      "LM_i1337_210127_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(86, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 191.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 cells are image driven - with overlap between images, \n",
      "        proportion 0.2 out of 688 cell-stim combos. \n",
      "        1-N image evokes resp from [23 23 15 19 14 13 15 17] cells\n",
      "50 cells are visually driven, \n",
      "        proportion 0.58 out of 86 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1337_210127_002_cellpose\n",
      "waiting for mat\n",
      "LM_i1337_210127_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 5) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 195.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 cells are image driven - with overlap between images, \n",
      "        proportion 0.26 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [16 19 16 21 12 17 12 15] cells\n",
      "41 cells are visually driven, \n",
      "        proportion 0.66 out of 62 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1337_210127_003_cellpose\n",
      "waiting for mat\n",
      "LI_i1337_210203_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(43, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 195.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 cells are image driven - with overlap between images, \n",
      "        proportion 0.15 out of 344 cell-stim combos. \n",
      "        1-N image evokes resp from [10  8  5  8  6  6  3  6] cells\n",
      "14 cells are visually driven, \n",
      "        proportion 0.33 out of 43 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1337_210203_003_cellpose\n",
      "waiting for mat\n",
      "LI_i1337_210203_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(25, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 195.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 cells are image driven - with overlap between images, \n",
      "        proportion 0.08 out of 200 cell-stim combos. \n",
      "        1-N image evokes resp from [1 1 2 0 3 2 5 2] cells\n",
      "5 cells are visually driven, \n",
      "        proportion 0.2 out of 25 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1337_210203_004_cellpose\n",
      "waiting for mat\n",
      "LM_i1338_210325_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(85, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 193.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 cells are image driven - with overlap between images, \n",
      "        proportion 0.07 out of 680 cell-stim combos. \n",
      "        1-N image evokes resp from [9 7 7 7 2 5 1 9] cells\n",
      "18 cells are visually driven, \n",
      "        proportion 0.21 out of 85 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1338_210325_002_cellpose\n",
      "waiting for mat\n",
      "LM_i1338_210805_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(80, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 195.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 640 cell-stim combos. \n",
      "        1-N image evokes resp from [18  6  9 11  5  7  4 13] cells\n",
      "29 cells are visually driven, \n",
      "        proportion 0.36 out of 80 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1338_210805_002_cellpose\n",
      "waiting for mat\n",
      "LI_i1339_210930_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(24, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 191.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 192 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 24 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1339_210930_002_cellpose\n",
      "waiting for mat\n",
      "LI_i1339_210930_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(25, 8, 4) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 205.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 200 cell-stim combos. \n",
      "        1-N image evokes resp from [1 0 0 0 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 25 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1339_210930_003_cellpose\n",
      "waiting for mat\n",
      "LM_i1350_211020_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 4) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 194.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 cells are image driven - with overlap between images, \n",
      "        proportion 0.01 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 1 0 1 1 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 62 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1350_211020_002_cellpose\n",
      "waiting for mat\n",
      "LM_i1350_211020_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(68, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 194.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 cells are image driven - with overlap between images, \n",
      "        proportion 0.04 out of 544 cell-stim combos. \n",
      "        1-N image evokes resp from [4 6 2 2 0 3 1 6] cells\n",
      "8 cells are visually driven, \n",
      "        proportion 0.12 out of 68 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1350_211020_003_cellpose\n",
      "waiting for mat\n",
      "LI_i1350_211028_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(35, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 194.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 280 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 35 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1350_211028_002_cellpose\n",
      "waiting for mat\n",
      "LI_i1350_211028_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(34, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 195.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 272 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "1 cells are visually driven, \n",
      "        proportion 0.03 out of 34 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1350_211028_003_cellpose\n",
      "waiting for mat\n",
      "LM_i1351_220228_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(63, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 193.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 504 cell-stim combos. \n",
      "        1-N image evokes resp from [ 9 10  5  6  3  0  8 16] cells\n",
      "30 cells are visually driven, \n",
      "        proportion 0.48 out of 63 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1351_220228_002_cellpose\n",
      "waiting for mat\n",
      "LM_i1351_220228_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(72, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 187.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 cells are image driven - with overlap between images, \n",
      "        proportion 0.05 out of 576 cell-stim combos. \n",
      "        1-N image evokes resp from [5 5 1 0 7 0 5 6] cells\n",
      "8 cells are visually driven, \n",
      "        proportion 0.11 out of 72 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1351_220228_003_cellpose\n",
      "waiting for mat\n",
      "LI_i1380_230110_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(35, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 197.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 280 cell-stim combos. \n",
      "        1-N image evokes resp from [3 4 6 2 3 5 5 5] cells\n",
      "9 cells are visually driven, \n",
      "        proportion 0.26 out of 35 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1380_230110_002_cellpose\n",
      "waiting for mat\n",
      "LI_i1380_230110_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(15, 8, 4) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 185.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 120 cell-stim combos. \n",
      "        1-N image evokes resp from [1 0 0 0 0 2 1 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 15 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1380_230110_003_cellpose\n",
      "waiting for mat\n",
      "LM_i1380_230221_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(67, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 196.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 536 cell-stim combos. \n",
      "        1-N image evokes resp from [2 2 2 4 4 0 2 2] cells\n",
      "3 cells are visually driven, \n",
      "        proportion 0.04 out of 67 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1380_230221_002_cellpose\n",
      "waiting for mat\n",
      "LM_i1380_230221_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(36, 8, 3) (20, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 196.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 288 cell-stim combos. \n",
      "        1-N image evokes resp from [1 0 0 0 1 1 1 2] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.06 out of 36 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1380_230221_003_cellpose\n",
      "waiting for mat\n",
      "LI_i1373_230228_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(73, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 194.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 cells are image driven - with overlap between images, \n",
      "        proportion 0.2 out of 584 cell-stim combos. \n",
      "        1-N image evokes resp from [17 14 12 21 19 14 11  9] cells\n",
      "38 cells are visually driven, \n",
      "        proportion 0.52 out of 73 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1373_230228_002_cellpose\n",
      "waiting for mat\n",
      "LI_i1373_230228_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(86, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 194.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 cells are image driven - with overlap between images, \n",
      "        proportion 0.07 out of 688 cell-stim combos. \n",
      "        1-N image evokes resp from [5 8 6 6 2 6 6 6] cells\n",
      "17 cells are visually driven, \n",
      "        proportion 0.2 out of 86 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1373_230228_003_cellpose\n",
      "waiting for mat\n",
      "LM_i1373_230302_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(139, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:00<00:00, 196.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 cells are image driven - with overlap between images, \n",
      "        proportion 0.23 out of 1112 cell-stim combos. \n",
      "        1-N image evokes resp from [33 25 30 41 37 33 29 26] cells\n",
      "109 cells are visually driven, \n",
      "        proportion 0.78 out of 139 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1373_230302_003_cellpose\n",
      "waiting for mat\n",
      "LM_i1373_230302_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(142, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 195.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 cells are image driven - with overlap between images, \n",
      "        proportion 0.23 out of 1136 cell-stim combos. \n",
      "        1-N image evokes resp from [28 34 35 29 32 36 34 31] cells\n",
      "93 cells are visually driven, \n",
      "        proportion 0.65 out of 142 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1373_230302_004_cellpose\n",
      "waiting for mat\n",
      "LM_i1381_230307_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(87, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 195.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 cells are image driven - with overlap between images, \n",
      "        proportion 0.14 out of 696 cell-stim combos. \n",
      "        1-N image evokes resp from [21 11 17  6  7  8 10 15] cells\n",
      "35 cells are visually driven, \n",
      "        proportion 0.4 out of 87 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1381_230307_002_cellpose\n",
      "waiting for mat\n",
      "LM_i1381_230307_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(98, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:00<00:00, 197.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 784 cell-stim combos. \n",
      "        1-N image evokes resp from [13  8 16  6 12 10 14 13] cells\n",
      "32 cells are visually driven, \n",
      "        proportion 0.33 out of 98 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1381_230307_003_cellpose\n",
      "waiting for mat\n",
      "LM_i1381_230307_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(100, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 197.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 800 cell-stim combos. \n",
      "        1-N image evokes resp from [5 0 2 0 1 2 1 4] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.02 out of 100 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1381_230307_004_cellpose\n",
      "waiting for mat\n",
      "LI_i1381_230309_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(94, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 195.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 cells are image driven - with overlap between images, \n",
      "        proportion 0.01 out of 752 cell-stim combos. \n",
      "        1-N image evokes resp from [1 0 2 3 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 94 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1381_230309_002_cellpose\n",
      "waiting for mat\n",
      "LI_i1381_230309_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(33, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 191.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 264 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 33 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1381_230309_003_cellpose\n"
     ]
    }
   ],
   "source": [
    "session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# session_mode = 'multi session' # no need to append irun to dir_sub\n",
    "\n",
    "## set up logging\n",
    "plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "# logging.basicConfig(filename='C:/Users/ll357/Documents/inter/data/vis_driven.log', level=logging.DEBUG)\n",
    "logging.basicConfig(filename=r'C:\\Users\\lan\\Documents\\repos\\inter\\data\\vis_driven.log'.replace('\\\\', '/'), level=logging.DEBUG)\n",
    "logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "logging.info(str(datetime.now()))\n",
    "\n",
    "for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "    # clear_output(wait=True)\n",
    "    logging.info(f'set {i+1} of {nset}')\n",
    "    mouse = meta.iloc[i].mouse.astype(str)\n",
    "    date = meta.iloc[i].date.astype(str)\n",
    "    area = meta.iloc[i].area\n",
    "    irun = meta.iloc[i].num # already a string due to concat lindsey's grating 8ori data\n",
    "    logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "    ## check if resp_base_trialwise exists\n",
    "    ## load data\n",
    "    logging.info('waiting for mat')\n",
    "    print('waiting for mat')\n",
    "    print('------------------')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            dir_sub = area + '_i' + mouse + '_' + date\n",
    "            if session_mode == 'single session':\n",
    "                dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "            print(dir_sub)\n",
    "            try: # manual seg data has no suffix '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            except: # cellpose seg data has suffix '_cellpose'\n",
    "                dir_sub += '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            logging.info('mat loaded')\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(60)\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "        isi_mode = 'only one isi'\n",
    "        print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "        dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "        dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "        isi_mode = 'grat_8ori_3isi'\n",
    "        print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "        dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "        dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "        print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "    ## stats\n",
    "    if isi_mode == 'only one isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_ad_trial.shape[0]\n",
    "        nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base_trial[icell, istim]\n",
    "                stim_cell = dfof_ad_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "    elif isi_mode == 'grat_8ori_3isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_tg_trial.shape[0]\n",
    "        nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "        # according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base2_trial[icell, istim]\n",
    "                stim_cell = dfof_tg_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "\n",
    "    # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "    p_sig = 0.05\n",
    "    evoked_thresh = 0.05\n",
    "    img_driven = (p_ttest < p_sig) & (evoked > evoked_thresh)\n",
    "    img_driven_msg = f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "        proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "        1-N image evokes resp from {np.sum(img_driven, axis=0)} cells'\n",
    "    logging.info(img_driven_msg)\n",
    "    print(img_driven_msg)\n",
    "\n",
    "    t = np.sum(img_driven, axis=1)\n",
    "    logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "    # visually driven cells\n",
    "    # NOTE changed to: driven by any image (pass t-test to any stim2, but with bonferroni correction) AND amp threshold. \n",
    "    loosen_sig = 1 # do not loosen\n",
    "    p_bonferroni_corrected = loosen_sig * p_sig / nstim # number of possible stim2\n",
    "    vis_driven = ((np.sum(p_ttest < p_bonferroni_corrected, axis=1) > 0) # any stim2 passes t-test\n",
    "                & (np.sum(evoked > evoked_thresh, axis=1) > 0) # any stim2 evokes resp > thresh\n",
    "                )\n",
    "    vis_driven_msg = f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells'\n",
    "    logging.info(vis_driven_msg)\n",
    "    print(vis_driven_msg)\n",
    "\n",
    "    # break\n",
    "\n",
    "    ## save\n",
    "    vis_driven_re = {}\n",
    "    # vis_driven_re['p_anova'] = p_anova\n",
    "    # vis_driven_re['p_kruskal'] = p_kruskal\n",
    "    vis_driven_re['p_ttest'] = p_ttest\n",
    "    vis_driven_re['evoked'] = evoked\n",
    "    vis_driven_re['p_sig'] = p_sig\n",
    "    vis_driven_re['p_bonferroni_corrected'] = p_bonferroni_corrected\n",
    "    vis_driven_re['vis_driven'] = vis_driven\n",
    "    vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "    os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "    print(os.getcwd())\n",
    "    with open('vis_driven_ttest_bonferroni_strict.pickle', 'wb') as f:\n",
    "        pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28c8c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05221402717506186,\n",
       " array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p_ttest.shape\n",
    "np.min(p_ttest), vis_driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcf66db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1337_210120_003_cellpose/'.replace('\\\\', '/')\n",
    "with open(pickle_dir+'vis_driven_ttest_bonferroni.pickle', 'rb') as f:\n",
    "    vis_driven_re = pickle.load(f)\n",
    "vis_driven_re['vis_driven'].shape\n",
    "\n",
    "import scipy.io as sio\n",
    "os.chdir(r'C:\\Users\\ll357\\Documents\\inter\\results\\tuning curve bias san check'.replace('\\\\', '/'))\n",
    "sio.savemat('vis_driven_ttest_bonferroni.mat', vis_driven_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4080456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64 cells are visually driven, \\n        proportion 0.62 out of 103 cells'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97097211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i1323_200720_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(103, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 393.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1323_200720_003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# # session_mode = 'multi session' # then irun must be appended to dir_sub !\n",
    "\n",
    "# ## set up logging\n",
    "# plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "# logging.basicConfig(filename='C:/Users/ll357/Documents/inter/data/vis_driven.log', level=logging.DEBUG)\n",
    "# logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "# logging.info(str(datetime.now()))\n",
    "\n",
    "# for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "#     # clear_output(wait=True)\n",
    "#     logging.info(f'set {i+1} of {nset}')\n",
    "#     mouse = meta.iloc[i].mouse.astype(str)\n",
    "#     date = meta.iloc[i].date.astype(str)\n",
    "#     area = meta.iloc[i].area\n",
    "#     irun = '00' + meta.iloc[i].num.astype(int).astype(str)\n",
    "#     logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "#     ## check if resp_base_trialwise exists\n",
    "#     ## load data\n",
    "#     logging.info('waiting for mat')\n",
    "#     print('waiting for mat')\n",
    "#     while True:\n",
    "#         try:\n",
    "#             dir_sub = area + '_i' + mouse + '_' + date\n",
    "#             if session_mode == 'single session':\n",
    "#                 dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "#             print(dir_sub)\n",
    "#             try: # manual seg data has no suffix '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             except: # cellpose seg data has suffix '_cellpose'\n",
    "#                 dir_sub += '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             logging.info('mat loaded')\n",
    "#             break\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             clear_output(wait=True)\n",
    "#             continue\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#         isi_mode = 'only one isi'\n",
    "#         print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#         dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#         dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#         isi_mode = 'grat_8ori_3isi'\n",
    "#         print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#         dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#         dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#         print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "#     ## stats\n",
    "#     if isi_mode == 'only one isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_ad_trial.shape[0]\n",
    "#         nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base_trial[icell, istim]\n",
    "#                 stim_cell = dfof_ad_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     elif isi_mode == 'grat_8ori_3isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_tg_trial.shape[0]\n",
    "#         nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base2_trial[icell, istim]\n",
    "#                 stim_cell = dfof_tg_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "#     p_sig = 0.05\n",
    "#     vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "#     logging.info(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#         proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "#     # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "#     img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "#     logging.info(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#         proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#         1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "#     t = np.sum(img_driven, axis=1)\n",
    "#     logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "#     ## save\n",
    "#     vis_driven_re = {}\n",
    "#     vis_driven_re['p_anova'] = p_anova\n",
    "#     vis_driven_re['p_kruskal'] = p_kruskal\n",
    "#     vis_driven_re['p_ttest'] = p_ttest\n",
    "#     vis_driven_re['evoked'] = evoked\n",
    "#     vis_driven_re['p_sig'] = p_sig\n",
    "#     vis_driven_re['vis_driven'] = vis_driven\n",
    "#     vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "#     os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "#     print(os.getcwd())\n",
    "#     with open('vis_driven.pickle', 'wb') as f:\n",
    "#         pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51fa8fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(base_cell_anova).flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a418769e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (18,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_cell_anova.__len__(), stim_cell_anova[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a103ca42",
   "metadata": {},
   "source": [
    "# depre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6659cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323 200721\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n"
     ]
    }
   ],
   "source": [
    "# # meta = pd.read_excel(mat_inter_path + 'adp_dataset_master.xlsx')\n",
    "\n",
    "# # date_str = str(200721)\n",
    "# # mouse_str = meta.loc[meta['date'] == int(date_str), 'mouse'].values#[0]\n",
    "# # area_str = meta.loc[meta['date'] == int(date_str), 'area'].values[0]\n",
    "# # if len(mouse_str) > 1:\n",
    "# #     print('duplicate dates with maybe different mouse. select which mouse?')\n",
    "# # else:\n",
    "# #     mouse_str = str(mouse_str[0])\n",
    "# # print(mouse_str, date_str)\n",
    "\n",
    "# try:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + '_cellpose'\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# except:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + ''\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#     mode = 'only one isi'\n",
    "#     print(f'mode is {mode} (only one isi, grat_SF or bunny)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#     dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#     dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#     mode = 'grat_8ori_3isi'\n",
    "#     print(f'mode is {mode} (grating with 8 orientations and 3 ISI)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#     dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#     dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#     print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b51367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 345.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# if mode == 'only one isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_ad_trial.shape[0]\n",
    "#     nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base_trial[icell, istim]\n",
    "#             stim_cell = dfof_ad_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "# elif mode == 'grat_8ori_3isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_tg_trial.shape[0]\n",
    "#     nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base2_trial[icell, istim]\n",
    "#             stim_cell = dfof_tg_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395531aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 cells are visually driven, \n",
      "    proportion 0.67 out of 39 cells\n",
      "29 cells are image driven - with overlap between images, \n",
      "    proportion 0.09 out of 312 cell-stim combos. \n",
      "    1-N image evokes resp from [4 2 6 1 3 2 5 6] cells\n",
      "img driven cells are driven by [1 2 2 1 2 1 1 1 2 1 2 1 4 1 1 1 1 3 1] images\n"
     ]
    }
   ],
   "source": [
    "# # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "# p_sig = 0.05\n",
    "# vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "# print(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#     proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "# # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "# img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "# print(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#     proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#     1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "# t = np.sum(img_driven, axis=1)\n",
    "# print(f'img driven cells are driven by {t[t>0]} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabf9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\duhs-user-nc1.dhe.duke.edu\\dusom_glickfeldlab\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721\n"
     ]
    }
   ],
   "source": [
    "# vis_driven_re = {}\n",
    "# vis_driven_re['p_anova'] = p_anova\n",
    "# vis_driven_re['p_kruskal'] = p_kruskal\n",
    "# vis_driven_re['p_ttest'] = p_ttest\n",
    "# vis_driven_re['evoked'] = evoked\n",
    "# vis_driven_re['p_sig'] = p_sig\n",
    "# vis_driven_re['vis_driven'] = vis_driven\n",
    "# vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "# os.chdir(os.path.join(mat_inter_path, dir_sub))\n",
    "# print(os.getcwd())\n",
    "\n",
    "# with open('vis_driven.pickle', 'wb') as f:\n",
    "#     pickle.dump(vis_driven_re, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "654a1d97444558a991daa59b50de40303e0e66ccc3f29b4958db12481daba1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
