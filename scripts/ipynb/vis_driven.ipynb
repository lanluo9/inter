{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f602c12f",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy.io import savemat\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f8eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>depth</th>\n",
       "      <th>num</th>\n",
       "      <th>cellpose_seg</th>\n",
       "      <th>manual_seg</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>gcamp</th>\n",
       "      <th>time</th>\n",
       "      <th>AWS</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1380</td>\n",
       "      <td>240206</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_2ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>951.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_2ori_multisess: ori = 22 or 0, isi = 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1380</td>\n",
       "      <td>240206</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_2ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>marked timestamp because lindsey use pdf not x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mouse    date area  depth  num  cellpose_seg manual_seg  \\\n",
       "165   1380  230622   V1    NaN  002           1.0        NaN   \n",
       "166   1380  230622   V1    NaN  003           1.0        NaN   \n",
       "167   1380  230622   V1    NaN  004           1.0        NaN   \n",
       "168   1380  240206   V1    NaN  002           1.0        NaN   \n",
       "169   1380  240206   V1    NaN  003           1.0        NaN   \n",
       "\n",
       "                   paradigm gcamp    time  AWS  \\\n",
       "165  grating_8ori_multisess    6s     NaN  NaN   \n",
       "166  grating_8ori_multisess    6s     NaN  NaN   \n",
       "167  grating_8ori_multisess    6s     NaN  NaN   \n",
       "168  grating_2ori_multisess    6s   951.0  NaN   \n",
       "169  grating_2ori_multisess    6s  1139.0  NaN   \n",
       "\n",
       "                                                  note  \n",
       "165                                                NaN  \n",
       "166                                                NaN  \n",
       "167                                                NaN  \n",
       "168  grating_2ori_multisess: ori = 22 or 0, isi = 6...  \n",
       "169  marked timestamp because lindsey use pdf not x...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_inter = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter/'.replace('\\\\', '/')\n",
    "dir_file = dir_inter + 'adp_dataset_master.xlsx'\n",
    "data_info = pd.read_excel(dir_file)\n",
    "data_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2a5d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>depth</th>\n",
       "      <th>num</th>\n",
       "      <th>cellpose_seg</th>\n",
       "      <th>manual_seg</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>gcamp</th>\n",
       "      <th>time</th>\n",
       "      <th>AWS</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1380</td>\n",
       "      <td>240206</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_2ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>951.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_2ori_multisess: ori = 22 or 0, isi = 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1380</td>\n",
       "      <td>240206</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_2ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>marked timestamp because lindsey use pdf not x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mouse    date area  depth  num  cellpose_seg manual_seg  \\\n",
       "0   1380  240206   V1    NaN  002           1.0        NaN   \n",
       "1   1380  240206   V1    NaN  003           1.0        NaN   \n",
       "\n",
       "                 paradigm gcamp    time  AWS  \\\n",
       "0  grating_2ori_multisess    6s   951.0  NaN   \n",
       "1  grating_2ori_multisess    6s  1139.0  NaN   \n",
       "\n",
       "                                                note  \n",
       "0  grating_2ori_multisess: ori = 22 or 0, isi = 6...  \n",
       "1  marked timestamp because lindsey use pdf not x...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = data_info[(data_info.paradigm == 'grating_2ori_multisess')\n",
    "                 & (data_info.gcamp == '6s') # avoid mixing in gcamp8f\n",
    "                #  & ((data_info.cellpose_seg == True) | (data_info.manual_seg == True)) # ensure segmentation\n",
    "                 ]\n",
    "\n",
    "meta = meta.reset_index(drop=True)\n",
    "nset = meta.shape[0]\n",
    "# print(meta.area.value_counts())\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c6e2c",
   "metadata": {},
   "source": [
    "# cell filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2deab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "------------------\n",
      "V1_i1380_240206\n",
      "isi_mode is only one isi (only one isi, grat_SF or bunny)\n",
      "(126, 2) (392, 1)\n",
      "only one isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 868.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 cells are image driven - with overlap between images, \n",
      "        proportion 0.4 out of 252 cell-stim combos. \n",
      "        1-N image evokes resp from [53 47] cells\n",
      "81 cells are visually driven, \n",
      "        proportion 0.64 out of 126 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1380_240206_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i1380_240206\n",
      "isi_mode is only one isi (only one isi, grat_SF or bunny)\n",
      "(126, 2) (392, 1)\n",
      "only one isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 862.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 cells are image driven - with overlap between images, \n",
      "        proportion 0.4 out of 252 cell-stim combos. \n",
      "        1-N image evokes resp from [53 47] cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 cells are visually driven, \n",
      "        proportion 0.64 out of 126 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1380_240206_cellpose\n"
     ]
    }
   ],
   "source": [
    "# session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "session_mode = 'multi session' # no need to append irun to dir_sub\n",
    "\n",
    "## set up logging\n",
    "plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "logging.basicConfig(filename=r'C:\\Users\\ll357\\Documents\\inter\\data\\vis_driven.log'.replace('\\\\', '/'), level=logging.DEBUG)\n",
    "logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "logging.info(str(datetime.now()))\n",
    "\n",
    "for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "    # clear_output(wait=True)\n",
    "    logging.info(f'set {i+1} of {nset}')\n",
    "    mouse = meta.iloc[i].mouse.astype(str)\n",
    "    date = meta.iloc[i].date.astype(str)\n",
    "    area = meta.iloc[i].area\n",
    "    irun = meta.iloc[i].num # already a string due to concat lindsey's grating 8ori data\n",
    "    logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "    ## check if resp_base_trialwise exists\n",
    "    ## load data\n",
    "    logging.info('waiting for mat')\n",
    "    print('waiting for mat')\n",
    "    print('------------------')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            dir_sub = area + '_i' + mouse + '_' + date\n",
    "            if session_mode == 'single session':\n",
    "                dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "            print(dir_sub)\n",
    "            try: # manual seg data has no suffix '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            except: # cellpose seg data has suffix '_cellpose'\n",
    "                dir_sub += '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            logging.info('mat loaded')\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(60)\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "        isi_mode = 'only one isi'\n",
    "        print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "        dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "        dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "        isi_mode = 'grat_8ori_3isi'\n",
    "        print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "        dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "        dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "        print('to find visually driven cells and image driven cells, take only no-adapter trials and use target response. \\n N possible target orientations will cover all needed cells')\n",
    "\n",
    "    ## stats\n",
    "    if isi_mode == 'only one isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_ad_trial.shape[0]\n",
    "        nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base_trial[icell, istim]\n",
    "                stim_cell = dfof_ad_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "    elif isi_mode == 'grat_8ori_3isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_tg_trial.shape[0]\n",
    "        nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base2_trial[icell, istim]\n",
    "                stim_cell = dfof_tg_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "\n",
    "    # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "    p_sig = 0.05\n",
    "    if area == 'LI':\n",
    "        p_sig = 0.1 # relax sig for LI. used for vis_driven_ttest_bonferroni_jeff.mat\n",
    "    evoked_thresh = 0.05\n",
    "    img_driven = (p_ttest < p_sig) & (evoked > evoked_thresh)\n",
    "    img_driven_msg = f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "        proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "        1-N image evokes resp from {np.sum(img_driven, axis=0)} cells'\n",
    "    logging.info(img_driven_msg)\n",
    "    print(img_driven_msg)\n",
    "\n",
    "    t = np.sum(img_driven, axis=1)\n",
    "    logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "    # visually driven cells\n",
    "    # NOTE changed to: driven by any image (pass t-test to any stim2, but with bonferroni correction) AND amp threshold. \n",
    "    loosen_sig = 1 # do not loosen, set ratio = 1\n",
    "    p_bonferroni_corrected = loosen_sig * p_sig / nstim # number of possible stim2\n",
    "    vis_driven = ((np.sum(p_ttest < p_bonferroni_corrected, axis=1) > 0) # any stim2 passes t-test\n",
    "                & (np.sum(evoked > evoked_thresh, axis=1) > 0) # AND any stim2 evokes resp > thresh\n",
    "                ) # bc vis filter = p_bonf & evoked_thresh, vis bool wont match vis_pval exactly in df_tidy! \n",
    "    vis_driven_msg = f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells'\n",
    "    logging.info(vis_driven_msg)\n",
    "    print(vis_driven_msg)\n",
    "\n",
    "    # break\n",
    "\n",
    "    ## save\n",
    "    vis_driven_re = {}\n",
    "    # vis_driven_re['p_anova'] = p_anova\n",
    "    # vis_driven_re['p_kruskal'] = p_kruskal\n",
    "    vis_driven_re['p_ttest'] = p_ttest\n",
    "    vis_driven_re['evoked'] = evoked\n",
    "    vis_driven_re['p_sig'] = p_sig\n",
    "    vis_driven_re['p_bonferroni_corrected'] = p_bonferroni_corrected\n",
    "    vis_driven_re['vis_driven'] = vis_driven\n",
    "    vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "    os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "    print(os.getcwd())\n",
    "    # savemat(\"vis_driven_ttest_bonferroni_jeff.mat\", vis_driven_re)\n",
    "    \n",
    "    with open('vis_driven_ttest_bonferroni.pickle', 'wb') as f:\n",
    "        pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97097211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i1323_200720_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(103, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 393.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1323_200720_003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# # session_mode = 'multi session' # then irun must be appended to dir_sub !\n",
    "\n",
    "# ## set up logging\n",
    "# plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "# logging.basicConfig(filename='C:/Users/ll357/Documents/inter/data/vis_driven.log', level=logging.DEBUG)\n",
    "# logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "# logging.info(str(datetime.now()))\n",
    "\n",
    "# for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "#     # clear_output(wait=True)\n",
    "#     logging.info(f'set {i+1} of {nset}')\n",
    "#     mouse = meta.iloc[i].mouse.astype(str)\n",
    "#     date = meta.iloc[i].date.astype(str)\n",
    "#     area = meta.iloc[i].area\n",
    "#     irun = '00' + meta.iloc[i].num.astype(int).astype(str)\n",
    "#     logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "#     ## check if resp_base_trialwise exists\n",
    "#     ## load data\n",
    "#     logging.info('waiting for mat')\n",
    "#     print('waiting for mat')\n",
    "#     while True:\n",
    "#         try:\n",
    "#             dir_sub = area + '_i' + mouse + '_' + date\n",
    "#             if session_mode == 'single session':\n",
    "#                 dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "#             print(dir_sub)\n",
    "#             try: # manual seg data has no suffix '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             except: # cellpose seg data has suffix '_cellpose'\n",
    "#                 dir_sub += '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             logging.info('mat loaded')\n",
    "#             break\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             clear_output(wait=True)\n",
    "#             continue\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#         isi_mode = 'only one isi'\n",
    "#         print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#         dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#         dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#         isi_mode = 'grat_8ori_3isi'\n",
    "#         print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#         dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#         dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#         print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "#     ## stats\n",
    "#     if isi_mode == 'only one isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_ad_trial.shape[0]\n",
    "#         nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base_trial[icell, istim]\n",
    "#                 stim_cell = dfof_ad_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     elif isi_mode == 'grat_8ori_3isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_tg_trial.shape[0]\n",
    "#         nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base2_trial[icell, istim]\n",
    "#                 stim_cell = dfof_tg_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "#     p_sig = 0.05\n",
    "#     vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "#     logging.info(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#         proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "#     # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "#     img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "#     logging.info(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#         proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#         1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "#     t = np.sum(img_driven, axis=1)\n",
    "#     logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "#     ## save\n",
    "#     vis_driven_re = {}\n",
    "#     vis_driven_re['p_anova'] = p_anova\n",
    "#     vis_driven_re['p_kruskal'] = p_kruskal\n",
    "#     vis_driven_re['p_ttest'] = p_ttest\n",
    "#     vis_driven_re['evoked'] = evoked\n",
    "#     vis_driven_re['p_sig'] = p_sig\n",
    "#     vis_driven_re['vis_driven'] = vis_driven\n",
    "#     vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "#     os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "#     print(os.getcwd())\n",
    "#     with open('vis_driven.pickle', 'wb') as f:\n",
    "#         pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "#     # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a103ca42",
   "metadata": {},
   "source": [
    "# depre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6659cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323 200721\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n"
     ]
    }
   ],
   "source": [
    "# # meta = pd.read_excel(mat_inter_path + 'adp_dataset_master.xlsx')\n",
    "\n",
    "# # date_str = str(200721)\n",
    "# # mouse_str = meta.loc[meta['date'] == int(date_str), 'mouse'].values#[0]\n",
    "# # area_str = meta.loc[meta['date'] == int(date_str), 'area'].values[0]\n",
    "# # if len(mouse_str) > 1:\n",
    "# #     print('duplicate dates with maybe different mouse. select which mouse?')\n",
    "# # else:\n",
    "# #     mouse_str = str(mouse_str[0])\n",
    "# # print(mouse_str, date_str)\n",
    "\n",
    "# try:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + '_cellpose'\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# except:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + ''\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#     mode = 'only one isi'\n",
    "#     print(f'mode is {mode} (only one isi, grat_SF or bunny)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#     dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#     dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#     mode = 'grat_8ori_3isi'\n",
    "#     print(f'mode is {mode} (grating with 8 orientations and 3 ISI)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#     dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#     dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#     print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b51367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 345.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# if mode == 'only one isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_ad_trial.shape[0]\n",
    "#     nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base_trial[icell, istim]\n",
    "#             stim_cell = dfof_ad_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "# elif mode == 'grat_8ori_3isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_tg_trial.shape[0]\n",
    "#     nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base2_trial[icell, istim]\n",
    "#             stim_cell = dfof_tg_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395531aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 cells are visually driven, \n",
      "    proportion 0.67 out of 39 cells\n",
      "29 cells are image driven - with overlap between images, \n",
      "    proportion 0.09 out of 312 cell-stim combos. \n",
      "    1-N image evokes resp from [4 2 6 1 3 2 5 6] cells\n",
      "img driven cells are driven by [1 2 2 1 2 1 1 1 2 1 2 1 4 1 1 1 1 3 1] images\n"
     ]
    }
   ],
   "source": [
    "# # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "# p_sig = 0.05\n",
    "# vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "# print(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#     proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "# # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "# img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "# print(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#     proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#     1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "# t = np.sum(img_driven, axis=1)\n",
    "# print(f'img driven cells are driven by {t[t>0]} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabf9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\duhs-user-nc1.dhe.duke.edu\\dusom_glickfeldlab\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721\n"
     ]
    }
   ],
   "source": [
    "# vis_driven_re = {}\n",
    "# vis_driven_re['p_anova'] = p_anova\n",
    "# vis_driven_re['p_kruskal'] = p_kruskal\n",
    "# vis_driven_re['p_ttest'] = p_ttest\n",
    "# vis_driven_re['evoked'] = evoked\n",
    "# vis_driven_re['p_sig'] = p_sig\n",
    "# vis_driven_re['vis_driven'] = vis_driven\n",
    "# vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "# os.chdir(os.path.join(mat_inter_path, dir_sub))\n",
    "# print(os.getcwd())\n",
    "\n",
    "# with open('vis_driven.pickle', 'wb') as f:\n",
    "#     pickle.dump(vis_driven_re, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "654a1d97444558a991daa59b50de40303e0e66ccc3f29b4958db12481daba1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
