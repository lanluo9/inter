{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy.io import savemat\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b650af2",
   "metadata": {},
   "source": [
    "# cell filter\n",
    "visually responsive & image driven "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f8eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>depth</th>\n",
       "      <th>num</th>\n",
       "      <th>cellpose_seg</th>\n",
       "      <th>manual_seg</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>gcamp</th>\n",
       "      <th>AWS</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>745</td>\n",
       "      <td>170816</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>746</td>\n",
       "      <td>170826</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>grating_lindsey_miaomiao</td>\n",
       "      <td>6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1380</td>\n",
       "      <td>230622</td>\n",
       "      <td>V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grating_8ori_multisess</td>\n",
       "      <td>6s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mouse    date area  depth      num  cellpose_seg manual_seg  \\\n",
       "163    745  170816   V1    NaN  002-003           NaN       True   \n",
       "164    746  170826   V1    NaN  002-003           NaN       True   \n",
       "165   1380  230622   V1    NaN      002           NaN        NaN   \n",
       "166   1380  230622   V1    NaN      003           NaN        NaN   \n",
       "167   1380  230622   V1    NaN      004           NaN        NaN   \n",
       "\n",
       "                     paradigm gcamp  AWS note  \n",
       "163  grating_lindsey_miaomiao    6f  NaN  NaN  \n",
       "164  grating_lindsey_miaomiao    6f  NaN  NaN  \n",
       "165    grating_8ori_multisess    6s  NaN  NaN  \n",
       "166    grating_8ori_multisess    6s  NaN  NaN  \n",
       "167    grating_8ori_multisess    6s  NaN  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_inter = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter/'.replace('\\\\', '/')\n",
    "dir_file = dir_inter + 'adp_dataset_master.xlsx'\n",
    "data_info = pd.read_excel(dir_file)\n",
    "data_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2a5d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area\n",
      "LM    22\n",
      "LI    18\n",
      "V1     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "meta = data_info[(data_info.paradigm == 'grating') # grating_8ori_multisess\n",
    "                 & (data_info.gcamp == '6s') # avoid mixing in gcamp8f\n",
    "                 & ((data_info.cellpose_seg == True) | (data_info.manual_seg == True)) # ensure segmentation\n",
    "                 ]\n",
    "\n",
    "meta = meta.reset_index(drop=True)\n",
    "nset = meta.shape[0]\n",
    "print(meta.area.value_counts())\n",
    "# meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2deab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "------------------\n",
      "V1_i1323_200720_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(103, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 214.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 cells are image driven - with overlap between images, \n",
      "        proportion 0.08 out of 824 cell-stim combos. \n",
      "        1-N image evokes resp from [ 5  4  8 12 10  6 12  8] cells\n",
      "26 cells are visually driven, \n",
      "        proportion 0.25 out of 103 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1323_200720_003\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1323_200721_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 220.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 cells are image driven - with overlap between images, \n",
      "        proportion 0.1 out of 312 cell-stim combos. \n",
      "        1-N image evokes resp from [5 1 6 2 3 2 6 6] cells\n",
      "21 cells are visually driven, \n",
      "        proportion 0.54 out of 39 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721_002\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1323_200723_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(33, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 189.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 cells are image driven - with overlap between images, \n",
      "        proportion 0.23 out of 264 cell-stim combos. \n",
      "        1-N image evokes resp from [ 5 14  6 10  5  3  8  9] cells\n",
      "18 cells are visually driven, \n",
      "        proportion 0.55 out of 33 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1323_200723_003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i1324_200728_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(93, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:00<00:00, 221.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 cells are image driven - with overlap between images, \n",
      "        proportion 0.19 out of 744 cell-stim combos. \n",
      "        1-N image evokes resp from [11 11 22 12 20 19 25 18] cells\n",
      "66 cells are visually driven, \n",
      "        proportion 0.71 out of 93 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1324_200728_003\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1324_200729_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(52, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 207.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 416 cell-stim combos. \n",
      "        1-N image evokes resp from [2 0 1 1 2 2 1 1] cells\n",
      "3 cells are visually driven, \n",
      "        proportion 0.06 out of 52 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1324_200729_003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i1322_200803_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(97, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 220.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 cells are image driven - with overlap between images, \n",
      "        proportion 0.18 out of 776 cell-stim combos. \n",
      "        1-N image evokes resp from [22 15 19 16 11 15 15 26] cells\n",
      "68 cells are visually driven, \n",
      "        proportion 0.7 out of 97 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1322_200803_002\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1322_200804_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(69, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:00<00:00, 220.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 cells are image driven - with overlap between images, \n",
      "        proportion 0.21 out of 552 cell-stim combos. \n",
      "        1-N image evokes resp from [16 15 13 17 17 16 13  8] cells\n",
      "38 cells are visually driven, \n",
      "        proportion 0.55 out of 69 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1322_200804_003\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1322_200806_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(53, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 218.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 cells are image driven - with overlap between images, \n",
      "        proportion 0.18 out of 424 cell-stim combos. \n",
      "        1-N image evokes resp from [ 4 11 12  6 18 17  3  6] cells\n",
      "22 cells are visually driven, \n",
      "        proportion 0.42 out of 53 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1322_200806_003\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i1328_201015_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(82, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 203.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 656 cell-stim combos. \n",
      "        1-N image evokes resp from [ 8 11  9 12 12  8 10 10] cells\n",
      "46 cells are visually driven, \n",
      "        proportion 0.56 out of 82 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1328_201015_004\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1328_201119_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(71, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:00<00:00, 220.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 cells are image driven - with overlap between images, \n",
      "        proportion 0.04 out of 568 cell-stim combos. \n",
      "        1-N image evokes resp from [1 8 2 2 1 0 4 3] cells\n",
      "7 cells are visually driven, \n",
      "        proportion 0.1 out of 71 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1328_201119_003\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1328_201127_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(40, 8, 4) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 219.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 cells are image driven - with overlap between images, \n",
      "        proportion 0.06 out of 320 cell-stim combos. \n",
      "        1-N image evokes resp from [2 3 4 2 2 2 1 3] cells\n",
      "17 cells are visually driven, \n",
      "        proportion 0.42 out of 40 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1328_201127_002\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1328_201202_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(9, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 209.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 cells are image driven - with overlap between images, \n",
      "        proportion 0.06 out of 72 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 3 0 0 1 0 0] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.22 out of 9 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1328_201202_003\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1328_201202_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(29, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 219.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 cells are image driven - with overlap between images, \n",
      "        proportion 0.07 out of 232 cell-stim combos. \n",
      "        1-N image evokes resp from [1 3 2 2 1 2 3 3] cells\n",
      "3 cells are visually driven, \n",
      "        proportion 0.1 out of 29 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1328_201202_004\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i1329_201209_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(146, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:00<00:00, 223.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 cells are image driven - with overlap between images, \n",
      "        proportion 0.09 out of 1168 cell-stim combos. \n",
      "        1-N image evokes resp from [16 15 11 17  6 12 11 20] cells\n",
      "33 cells are visually driven, \n",
      "        proportion 0.23 out of 146 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1329_201209_002\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1329_201217_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(107, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 219.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 cells are image driven - with overlap between images, \n",
      "        proportion 0.13 out of 856 cell-stim combos. \n",
      "        1-N image evokes resp from [14 12 14 14 16 13 15 17] cells\n",
      "43 cells are visually driven, \n",
      "        proportion 0.4 out of 107 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1329_201217_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1329_201217_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(90, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 225.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 720 cell-stim combos. \n",
      "        1-N image evokes resp from [13 11  9  8  9  5  9 12] cells\n",
      "21 cells are visually driven, \n",
      "        proportion 0.23 out of 90 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1329_201217_004_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1329_210113_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(22, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 215.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 cells are image driven - with overlap between images, \n",
      "        proportion 0.04 out of 176 cell-stim combos. \n",
      "        1-N image evokes resp from [0 1 1 1 1 0 2 1] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.09 out of 22 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1329_210113_004_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1329_210113_006\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(23, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 216.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 184 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 1 1 1 0 0] cells\n",
      "1 cells are visually driven, \n",
      "        proportion 0.04 out of 23 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1329_210113_006_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "V1_i1337_210120_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 220.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 cells are image driven - with overlap between images, \n",
      "        proportion 0.24 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [14 18  8 15 13 12 22 19] cells\n",
      "45 cells are visually driven, \n",
      "        proportion 0.73 out of 62 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1337_210120_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1337_210127_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(86, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 223.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 cells are image driven - with overlap between images, \n",
      "        proportion 0.2 out of 688 cell-stim combos. \n",
      "        1-N image evokes resp from [23 23 15 19 14 13 15 17] cells\n",
      "50 cells are visually driven, \n",
      "        proportion 0.58 out of 86 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1337_210127_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1337_210127_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 5) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 221.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 cells are image driven - with overlap between images, \n",
      "        proportion 0.26 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [16 19 16 21 12 17 12 15] cells\n",
      "41 cells are visually driven, \n",
      "        proportion 0.66 out of 62 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1337_210127_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1337_210203_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(43, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 226.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 cells are image driven - with overlap between images, \n",
      "        proportion 0.19 out of 344 cell-stim combos. \n",
      "        1-N image evokes resp from [12  9  8  9  8  7  4  8] cells\n",
      "19 cells are visually driven, \n",
      "        proportion 0.44 out of 43 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1337_210203_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1337_210203_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(25, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 219.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 200 cell-stim combos. \n",
      "        1-N image evokes resp from [2 2 3 0 4 3 5 4] cells\n",
      "6 cells are visually driven, \n",
      "        proportion 0.24 out of 25 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1337_210203_004_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1338_210325_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(85, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 215.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 cells are image driven - with overlap between images, \n",
      "        proportion 0.07 out of 680 cell-stim combos. \n",
      "        1-N image evokes resp from [9 7 7 7 2 5 1 9] cells\n",
      "18 cells are visually driven, \n",
      "        proportion 0.21 out of 85 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1338_210325_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1338_210805_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(80, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 220.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 640 cell-stim combos. \n",
      "        1-N image evokes resp from [18  6  9 11  5  7  4 13] cells\n",
      "29 cells are visually driven, \n",
      "        proportion 0.36 out of 80 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1338_210805_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1339_210930_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(24, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 214.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 192 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 24 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1339_210930_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1339_210930_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(25, 8, 4) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 221.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 200 cell-stim combos. \n",
      "        1-N image evokes resp from [2 0 0 0 0 0 0 1] cells\n",
      "1 cells are visually driven, \n",
      "        proportion 0.04 out of 25 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1339_210930_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1350_211020_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 4) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 226.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 cells are image driven - with overlap between images, \n",
      "        proportion 0.01 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 1 0 1 1 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 62 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1350_211020_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1350_211020_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(68, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 218.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 cells are image driven - with overlap between images, \n",
      "        proportion 0.04 out of 544 cell-stim combos. \n",
      "        1-N image evokes resp from [4 6 2 2 0 3 1 6] cells\n",
      "8 cells are visually driven, \n",
      "        proportion 0.12 out of 68 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1350_211020_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1350_211028_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(35, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 222.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 280 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 35 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1350_211028_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1350_211028_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(34, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 202.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 cells are image driven - with overlap between images, \n",
      "        proportion 0.01 out of 272 cell-stim combos. \n",
      "        1-N image evokes resp from [0 1 0 0 1 0 0 0] cells\n",
      "1 cells are visually driven, \n",
      "        proportion 0.03 out of 34 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1350_211028_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1351_220228_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(63, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 221.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 504 cell-stim combos. \n",
      "        1-N image evokes resp from [ 9 10  5  6  3  0  8 16] cells\n",
      "30 cells are visually driven, \n",
      "        proportion 0.48 out of 63 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1351_220228_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1351_220228_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(72, 8, 3) (16, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 215.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 cells are image driven - with overlap between images, \n",
      "        proportion 0.05 out of 576 cell-stim combos. \n",
      "        1-N image evokes resp from [5 5 1 0 7 0 5 6] cells\n",
      "8 cells are visually driven, \n",
      "        proportion 0.11 out of 72 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1351_220228_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1380_230110_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(35, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 218.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 cells are image driven - with overlap between images, \n",
      "        proportion 0.15 out of 280 cell-stim combos. \n",
      "        1-N image evokes resp from [5 5 7 2 4 6 7 5] cells\n",
      "9 cells are visually driven, \n",
      "        proportion 0.26 out of 35 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1380_230110_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1380_230110_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(15, 8, 4) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 208.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 120 cell-stim combos. \n",
      "        1-N image evokes resp from [1 0 0 0 0 2 1 0] cells\n",
      "1 cells are visually driven, \n",
      "        proportion 0.07 out of 15 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1380_230110_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1380_230221_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(67, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 220.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 536 cell-stim combos. \n",
      "        1-N image evokes resp from [2 2 2 4 4 0 2 2] cells\n",
      "3 cells are visually driven, \n",
      "        proportion 0.04 out of 67 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1380_230221_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1380_230221_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(36, 8, 3) (20, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 224.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 288 cell-stim combos. \n",
      "        1-N image evokes resp from [1 0 0 0 1 1 1 2] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.06 out of 36 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1380_230221_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1373_230228_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(73, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 223.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 cells are image driven - with overlap between images, \n",
      "        proportion 0.24 out of 584 cell-stim combos. \n",
      "        1-N image evokes resp from [21 18 15 24 23 15 14 13] cells\n",
      "43 cells are visually driven, \n",
      "        proportion 0.59 out of 73 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1373_230228_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1373_230228_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(86, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 224.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 cells are image driven - with overlap between images, \n",
      "        proportion 0.1 out of 688 cell-stim combos. \n",
      "        1-N image evokes resp from [ 6 10  8 13  3  9  8 15] cells\n",
      "21 cells are visually driven, \n",
      "        proportion 0.24 out of 86 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1373_230228_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1373_230302_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(139, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:00<00:00, 224.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 cells are image driven - with overlap between images, \n",
      "        proportion 0.23 out of 1112 cell-stim combos. \n",
      "        1-N image evokes resp from [33 25 30 41 37 33 29 26] cells\n",
      "109 cells are visually driven, \n",
      "        proportion 0.78 out of 139 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1373_230302_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1373_230302_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(142, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 222.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 cells are image driven - with overlap between images, \n",
      "        proportion 0.23 out of 1136 cell-stim combos. \n",
      "        1-N image evokes resp from [28 34 35 29 32 36 34 31] cells\n",
      "93 cells are visually driven, \n",
      "        proportion 0.65 out of 142 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1373_230302_004_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1381_230307_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(87, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 222.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 cells are image driven - with overlap between images, \n",
      "        proportion 0.14 out of 696 cell-stim combos. \n",
      "        1-N image evokes resp from [21 11 17  6  7  8 10 15] cells\n",
      "35 cells are visually driven, \n",
      "        proportion 0.4 out of 87 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1381_230307_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1381_230307_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(98, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:00<00:00, 223.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 cells are image driven - with overlap between images, \n",
      "        proportion 0.12 out of 784 cell-stim combos. \n",
      "        1-N image evokes resp from [13  8 16  6 12 10 14 13] cells\n",
      "32 cells are visually driven, \n",
      "        proportion 0.33 out of 98 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1381_230307_003_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LM_i1381_230307_004\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(100, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 220.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 800 cell-stim combos. \n",
      "        1-N image evokes resp from [5 0 2 0 1 2 1 4] cells\n",
      "2 cells are visually driven, \n",
      "        proportion 0.02 out of 100 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1381_230307_004_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1381_230309_002\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(94, 8, 3) (19, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 224.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 752 cell-stim combos. \n",
      "        1-N image evokes resp from [2 2 4 4 4 0 0 1] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 94 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1381_230309_002_cellpose\n",
      "waiting for mat\n",
      "------------------\n",
      "LI_i1381_230309_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(33, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 214.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 cells are image driven - with overlap between images, \n",
      "        proportion 0.01 out of 264 cell-stim combos. \n",
      "        1-N image evokes resp from [0 1 1 0 0 0 0 0] cells\n",
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 33 cells\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1381_230309_003_cellpose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# session_mode = 'multi session' # no need to append irun to dir_sub\n",
    "\n",
    "## set up logging\n",
    "plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "logging.basicConfig(filename=r'C:\\Users\\ll357\\Documents\\inter\\data\\vis_driven.log'.replace('\\\\', '/'), level=logging.DEBUG)\n",
    "logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "logging.info(str(datetime.now()))\n",
    "\n",
    "for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "    # clear_output(wait=True)\n",
    "    logging.info(f'set {i+1} of {nset}')\n",
    "    mouse = meta.iloc[i].mouse.astype(str)\n",
    "    date = meta.iloc[i].date.astype(str)\n",
    "    area = meta.iloc[i].area\n",
    "    irun = meta.iloc[i].num # already a string due to concat lindsey's grating 8ori data\n",
    "    logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "    ## check if resp_base_trialwise exists\n",
    "    ## load data\n",
    "    logging.info('waiting for mat')\n",
    "    print('waiting for mat')\n",
    "    print('------------------')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            dir_sub = area + '_i' + mouse + '_' + date\n",
    "            if session_mode == 'single session':\n",
    "                dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "            print(dir_sub)\n",
    "            try: # manual seg data has no suffix '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            except: # cellpose seg data has suffix '_cellpose'\n",
    "                dir_sub += '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "            logging.info('mat loaded')\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(60)\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "        isi_mode = 'only one isi'\n",
    "        print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "        dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "        dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "        isi_mode = 'grat_8ori_3isi'\n",
    "        print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "        dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "        dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "        print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "    ## stats\n",
    "    if isi_mode == 'only one isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_ad_trial.shape[0]\n",
    "        nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base_trial[icell, istim]\n",
    "                stim_cell = dfof_ad_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "    elif isi_mode == 'grat_8ori_3isi':\n",
    "        print(isi_mode)\n",
    "\n",
    "        ncell = dfof_tg_trial.shape[0]\n",
    "        nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "        # according to Ohki 2020\n",
    "        # p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        # p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base2_trial[icell, istim]\n",
    "                stim_cell = dfof_tg_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            # _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_anova[icell] = p_anova_cell\n",
    "            # _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            # p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "\n",
    "    # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "    p_sig = 0.05\n",
    "    if area == 'LI':\n",
    "        p_sig = 0.1 # relax sig for LI. used for vis_driven_ttest_bonferroni_jeff.mat\n",
    "    evoked_thresh = 0.05\n",
    "    img_driven = (p_ttest < p_sig) & (evoked > evoked_thresh)\n",
    "    img_driven_msg = f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "        proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "        1-N image evokes resp from {np.sum(img_driven, axis=0)} cells'\n",
    "    logging.info(img_driven_msg)\n",
    "    print(img_driven_msg)\n",
    "\n",
    "    t = np.sum(img_driven, axis=1)\n",
    "    logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "    # visually driven cells\n",
    "    # NOTE changed to: driven by any image (pass t-test to any stim2, but with bonferroni correction) AND amp threshold. \n",
    "    loosen_sig = 1 # do not loosen, set ratio = 1\n",
    "    p_bonferroni_corrected = loosen_sig * p_sig / nstim # number of possible stim2\n",
    "    vis_driven = ((np.sum(p_ttest < p_bonferroni_corrected, axis=1) > 0) # any stim2 passes t-test\n",
    "                & (np.sum(evoked > evoked_thresh, axis=1) > 0) # any stim2 evokes resp > thresh\n",
    "                )\n",
    "    vis_driven_msg = f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells'\n",
    "    logging.info(vis_driven_msg)\n",
    "    print(vis_driven_msg)\n",
    "\n",
    "    # break\n",
    "\n",
    "    ## save\n",
    "    vis_driven_re = {}\n",
    "    # vis_driven_re['p_anova'] = p_anova\n",
    "    # vis_driven_re['p_kruskal'] = p_kruskal\n",
    "    vis_driven_re['p_ttest'] = p_ttest\n",
    "    vis_driven_re['evoked'] = evoked\n",
    "    vis_driven_re['p_sig'] = p_sig\n",
    "    vis_driven_re['p_bonferroni_corrected'] = p_bonferroni_corrected\n",
    "    vis_driven_re['vis_driven'] = vis_driven\n",
    "    vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "    os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "    print(os.getcwd())\n",
    "    savemat(\"vis_driven_ttest_bonferroni_jeff.mat\", vis_driven_re)\n",
    "    \n",
    "    # with open('vis_driven_ttest_bonferroni_strict.pickle', 'wb') as f:\n",
    "    #     pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97097211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for mat\n",
      "V1_i1323_200720_003\n",
      "isi_mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(103, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 393.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\V1_i1323_200720_003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# session_mode = 'single session' # then irun must be appended to dir_sub !\n",
    "# # session_mode = 'multi session' # then irun must be appended to dir_sub !\n",
    "\n",
    "# ## set up logging\n",
    "# plt.set_loglevel(level='warning') # turn off matplotlib debug logging\n",
    "# logging.basicConfig(filename='C:/Users/ll357/Documents/inter/data/vis_driven.log', level=logging.DEBUG)\n",
    "# logging.info('\\n\\n\\n\\n\\n') # log several linebreaks to separate different runs\n",
    "# logging.info(str(datetime.now()))\n",
    "\n",
    "# for i in np.arange(nset): # TODO: this overwrites vis-driven.pickle multiple times for multisess data, fix later\n",
    "#     # clear_output(wait=True)\n",
    "#     logging.info(f'set {i+1} of {nset}')\n",
    "#     mouse = meta.iloc[i].mouse.astype(str)\n",
    "#     date = meta.iloc[i].date.astype(str)\n",
    "#     area = meta.iloc[i].area\n",
    "#     irun = '00' + meta.iloc[i].num.astype(int).astype(str)\n",
    "#     logging.info(f'{mouse} {date} {irun} {area}')\n",
    "\n",
    "#     ## check if resp_base_trialwise exists\n",
    "#     ## load data\n",
    "#     logging.info('waiting for mat')\n",
    "#     print('waiting for mat')\n",
    "#     while True:\n",
    "#         try:\n",
    "#             dir_sub = area + '_i' + mouse + '_' + date\n",
    "#             if session_mode == 'single session':\n",
    "#                 dir_sub += '_' + irun # else: multi sess, dont append irun\n",
    "#             print(dir_sub)\n",
    "#             try: # manual seg data has no suffix '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             except: # cellpose seg data has suffix '_cellpose'\n",
    "#                 dir_sub += '_cellpose'\n",
    "#                 dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat'))\n",
    "#             logging.info('mat loaded')\n",
    "#             break\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             clear_output(wait=True)\n",
    "#             continue\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#         isi_mode = 'only one isi'\n",
    "#         print(f'isi_mode is {isi_mode} (only one isi, grat_SF or bunny)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#         dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#         dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "#     if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#         isi_mode = 'grat_8ori_3isi'\n",
    "#         print(f'isi_mode is {isi_mode} (grating with 8 orientations and 3 ISI)')\n",
    "#         print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#         dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#         dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#         print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "#     ## stats\n",
    "#     if isi_mode == 'only one isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_ad_trial.shape[0]\n",
    "#         nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base_trial[icell, istim]\n",
    "#                 stim_cell = dfof_ad_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     elif isi_mode == 'grat_8ori_3isi':\n",
    "#         print(isi_mode)\n",
    "\n",
    "#         ncell = dfof_tg_trial.shape[0]\n",
    "#         nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#         ## according to Ohki 2020\n",
    "#         p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#         p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#         p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#         evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#         for icell in tqdm(np.arange(ncell)):\n",
    "#             base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#             stim_cell_anova = [] \n",
    "#             for istim in np.arange(nstim):\n",
    "#                 stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#                 base_cell = dfof_base2_trial[icell, istim]\n",
    "#                 stim_cell = dfof_tg_trial[icell, istim]\n",
    "#                 _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#                 p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#                 evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#                 evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#                 evoked[icell, istim] = evoked_i\n",
    "            \n",
    "#             _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_anova[icell] = p_anova_cell\n",
    "#             _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#             p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "#     # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "#     p_sig = 0.05\n",
    "#     vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "#     logging.info(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#         proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "#     # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "#     img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "#     logging.info(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#         proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#         1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "#     t = np.sum(img_driven, axis=1)\n",
    "#     logging.info(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "#     ## save\n",
    "#     vis_driven_re = {}\n",
    "#     vis_driven_re['p_anova'] = p_anova\n",
    "#     vis_driven_re['p_kruskal'] = p_kruskal\n",
    "#     vis_driven_re['p_ttest'] = p_ttest\n",
    "#     vis_driven_re['evoked'] = evoked\n",
    "#     vis_driven_re['p_sig'] = p_sig\n",
    "#     vis_driven_re['vis_driven'] = vis_driven\n",
    "#     vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "#     os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "#     print(os.getcwd())\n",
    "#     with open('vis_driven.pickle', 'wb') as f:\n",
    "#         pickle.dump(vis_driven_re, f)\n",
    "    \n",
    "#     # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a103ca42",
   "metadata": {},
   "source": [
    "# depre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6659cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323 200721\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n"
     ]
    }
   ],
   "source": [
    "# # meta = pd.read_excel(mat_inter_path + 'adp_dataset_master.xlsx')\n",
    "\n",
    "# # date_str = str(200721)\n",
    "# # mouse_str = meta.loc[meta['date'] == int(date_str), 'mouse'].values#[0]\n",
    "# # area_str = meta.loc[meta['date'] == int(date_str), 'area'].values[0]\n",
    "# # if len(mouse_str) > 1:\n",
    "# #     print('duplicate dates with maybe different mouse. select which mouse?')\n",
    "# # else:\n",
    "# #     mouse_str = str(mouse_str[0])\n",
    "# # print(mouse_str, date_str)\n",
    "\n",
    "# try:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + '_cellpose'\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# except:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + ''\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#     mode = 'only one isi'\n",
    "#     print(f'mode is {mode} (only one isi, grat_SF or bunny)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#     dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#     dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#     mode = 'grat_8ori_3isi'\n",
    "#     print(f'mode is {mode} (grating with 8 orientations and 3 ISI)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#     dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#     dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#     print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b51367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 345.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# if mode == 'only one isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_ad_trial.shape[0]\n",
    "#     nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base_trial[icell, istim]\n",
    "#             stim_cell = dfof_ad_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "# elif mode == 'grat_8ori_3isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_tg_trial.shape[0]\n",
    "#     nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base2_trial[icell, istim]\n",
    "#             stim_cell = dfof_tg_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395531aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 cells are visually driven, \n",
      "    proportion 0.67 out of 39 cells\n",
      "29 cells are image driven - with overlap between images, \n",
      "    proportion 0.09 out of 312 cell-stim combos. \n",
      "    1-N image evokes resp from [4 2 6 1 3 2 5 6] cells\n",
      "img driven cells are driven by [1 2 2 1 2 1 1 1 2 1 2 1 4 1 1 1 1 3 1] images\n"
     ]
    }
   ],
   "source": [
    "# # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "# p_sig = 0.05\n",
    "# vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "# print(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#     proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "# # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "# img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "# print(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#     proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#     1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "# t = np.sum(img_driven, axis=1)\n",
    "# print(f'img driven cells are driven by {t[t>0]} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabf9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\duhs-user-nc1.dhe.duke.edu\\dusom_glickfeldlab\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721\n"
     ]
    }
   ],
   "source": [
    "# vis_driven_re = {}\n",
    "# vis_driven_re['p_anova'] = p_anova\n",
    "# vis_driven_re['p_kruskal'] = p_kruskal\n",
    "# vis_driven_re['p_ttest'] = p_ttest\n",
    "# vis_driven_re['evoked'] = evoked\n",
    "# vis_driven_re['p_sig'] = p_sig\n",
    "# vis_driven_re['vis_driven'] = vis_driven\n",
    "# vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "# os.chdir(os.path.join(mat_inter_path, dir_sub))\n",
    "# print(os.getcwd())\n",
    "\n",
    "# with open('vis_driven.pickle', 'wb') as f:\n",
    "#     pickle.dump(vis_driven_re, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "654a1d97444558a991daa59b50de40303e0e66ccc3f29b4958db12481daba1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
