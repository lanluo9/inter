{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97097211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set  1 of 36\n",
      "1323 200721 002 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 330.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 cells are visually driven, \n",
      "        proportion 0.69 out of 39 cells\n",
      "28 cells are image driven - with overlap between images, \n",
      "        proportion 0.09 out of 312 cell-stim combos. \n",
      "        1-N image evokes resp from [3 1 6 2 2 2 6 6] cells\n",
      "img driven cells are driven by [1 2 1 1 2 2 1 2 2 2 2 3 1 1 2 2 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721\n",
      "set  2 of 36\n",
      "1323 200723 003 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(33, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 383.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 cells are visually driven, \n",
      "        proportion 0.82 out of 33 cells\n",
      "40 cells are image driven - with overlap between images, \n",
      "        proportion 0.15 out of 264 cell-stim combos. \n",
      "        1-N image evokes resp from [ 3 10  5  6  3  0  5  8] cells\n",
      "img driven cells are driven by [1 1 2 1 2 1 1 4 1 2 2 1 2 4 2 1 3 4 2 2 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1323_200723\n",
      "set  3 of 36\n",
      "1324 200729 003 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(52, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 385.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cells are visually driven, \n",
      "        proportion 0.23 out of 52 cells\n",
      "8 cells are image driven - with overlap between images, \n",
      "        proportion 0.02 out of 416 cell-stim combos. \n",
      "        1-N image evokes resp from [1 0 1 1 2 1 1 1] cells\n",
      "img driven cells are driven by [1 5 1 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1324_200729\n",
      "set  4 of 36\n",
      "1322 200804 003 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(69, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:00<00:00, 380.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 cells are visually driven, \n",
      "        proportion 0.88 out of 69 cells\n",
      "113 cells are image driven - with overlap between images, \n",
      "        proportion 0.2 out of 552 cell-stim combos. \n",
      "        1-N image evokes resp from [16 15 13 17 16 16 13  7] cells\n",
      "img driven cells are driven by [4 2 1 1 2 7 3 2 3 4 2 1 5 1 1 2 1 1 3 3 4 2 1 1 5 2 1 4 1 1 3 1 2 2 4 2 1\n",
      " 4 4 1 2 1 2 1 1 3 2 1 1 3 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1322_200804\n",
      "set  5 of 36\n",
      "1322 200806 003 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(53, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 376.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 cells are visually driven, \n",
      "        proportion 0.68 out of 53 cells\n",
      "54 cells are image driven - with overlap between images, \n",
      "        proportion 0.13 out of 424 cell-stim combos. \n",
      "        1-N image evokes resp from [ 2  7  7  4 12 16  1  5] cells\n",
      "img driven cells are driven by [2 3 3 1 1 2 2 3 1 1 1 1 1 3 2 3 1 2 1 2 1 4 4 2 2 4 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1322_200806\n",
      "set  6 of 36\n",
      "1328 201119 003 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(71, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:00<00:00, 360.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 cells are visually driven, \n",
      "        proportion 0.32 out of 71 cells\n",
      "16 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 568 cell-stim combos. \n",
      "        1-N image evokes resp from [1 5 2 2 1 0 3 2] cells\n",
      "img driven cells are driven by [1 2 2 1 1 1 2 2 1 1 1 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1328_201119\n",
      "set  7 of 36\n",
      "1328 201127 002 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(40, 8, 4) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 400.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 cells are visually driven, \n",
      "        proportion 0.7 out of 40 cells\n",
      "17 cells are image driven - with overlap between images, \n",
      "        proportion 0.05 out of 320 cell-stim combos. \n",
      "        1-N image evokes resp from [1 3 4 2 2 2 0 3] cells\n",
      "img driven cells are driven by [1 2 1 1 1 1 2 2 2 1 2 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1328_201127\n",
      "set  8 of 36\n",
      "1328 201202 003 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(29, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 367.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 cells are visually driven, \n",
      "        proportion 0.38 out of 29 cells\n",
      "8 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 232 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 2 0 1 1 2 2] cells\n",
      "img driven cells are driven by [1 2 4 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1328_201202\n",
      "set  9 of 36\n",
      "1328 201202 004 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(29, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 380.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 cells are visually driven, \n",
      "        proportion 0.38 out of 29 cells\n",
      "8 cells are image driven - with overlap between images, \n",
      "        proportion 0.03 out of 232 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 2 0 1 1 2 2] cells\n",
      "img driven cells are driven by [1 2 4 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1328_201202\n",
      "set  10 of 36\n",
      "1329 201217 002 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(90, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 354.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 cells are visually driven, \n",
      "        proportion 0.62 out of 90 cells\n",
      "76 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 720 cell-stim combos. \n",
      "        1-N image evokes resp from [13 11  9  8  9  5  9 12] cells\n",
      "img driven cells are driven by [5 1 1 6 1 2 2 6 2 1 1 1 1 2 2 1 3 2 2 2 1 2 3 4 2 1 1 4 1 2 1 2 4 1 1 2] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1329_201217_cellpose\n",
      "set  11 of 36\n",
      "1329 201217 004 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(90, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 361.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 cells are visually driven, \n",
      "        proportion 0.62 out of 90 cells\n",
      "76 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 720 cell-stim combos. \n",
      "        1-N image evokes resp from [13 11  9  8  9  5  9 12] cells\n",
      "img driven cells are driven by [5 1 1 6 1 2 2 6 2 1 1 1 1 2 2 1 3 2 2 2 1 2 3 4 2 1 1 4 1 2 1 2 4 1 1 2] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1329_201217_cellpose\n",
      "set  12 of 36\n",
      "1329 210113 004 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(6, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 315.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 6 cells\n",
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 48 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "img driven cells are driven by [] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1329_210113_cellpose\n",
      "set  13 of 36\n",
      "1329 210113 006 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(6, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 315.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cells are visually driven, \n",
      "        proportion 0.0 out of 6 cells\n",
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 48 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "img driven cells are driven by [] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1329_210113_cellpose\n",
      "set  14 of 36\n",
      "1337 210127 002 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 5) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 369.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 cells are visually driven, \n",
      "        proportion 0.9 out of 62 cells\n",
      "125 cells are image driven - with overlap between images, \n",
      "        proportion 0.25 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [15 18 16 21 12 16 12 15] cells\n",
      "img driven cells are driven by [4 2 1 2 1 3 1 3 1 3 5 2 4 4 2 2 3 2 3 2 3 2 3 4 4 5 2 1 4 1 1 4 6 1 2 5 3\n",
      " 3 3 5 2 3 1 2 4 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1337_210127_cellpose\n",
      "set  15 of 36\n",
      "1337 210127 003 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(62, 8, 5) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 366.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 cells are visually driven, \n",
      "        proportion 0.9 out of 62 cells\n",
      "125 cells are image driven - with overlap between images, \n",
      "        proportion 0.25 out of 496 cell-stim combos. \n",
      "        1-N image evokes resp from [15 18 16 21 12 16 12 15] cells\n",
      "img driven cells are driven by [4 2 1 2 1 3 1 3 1 3 5 2 4 4 2 2 3 2 3 2 3 2 3 4 4 5 2 1 4 1 1 4 6 1 2 5 3\n",
      " 3 3 5 2 3 1 2 4 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1337_210127_cellpose\n",
      "set  16 of 36\n",
      "1337 210203 003 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(20, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 386.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 cells are visually driven, \n",
      "        proportion 0.1 out of 20 cells\n",
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 160 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "img driven cells are driven by [] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1337_210203_cellpose\n",
      "set  17 of 36\n",
      "1337 210203 004 LI\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(20, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 453.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 cells are visually driven, \n",
      "        proportion 0.1 out of 20 cells\n",
      "0 cells are image driven - with overlap between images, \n",
      "        proportion 0.0 out of 160 cell-stim combos. \n",
      "        1-N image evokes resp from [0 0 0 0 0 0 0 0] cells\n",
      "img driven cells are driven by [] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LI_i1337_210203_cellpose\n",
      "set  18 of 36\n",
      "1338 210325 002 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(85, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 375.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 cells are visually driven, \n",
      "        proportion 0.52 out of 85 cells\n",
      "43 cells are image driven - with overlap between images, \n",
      "        proportion 0.06 out of 680 cell-stim combos. \n",
      "        1-N image evokes resp from [9 6 6 6 2 5 1 8] cells\n",
      "img driven cells are driven by [2 1 1 4 1 1 1 1 2 1 2 1 2 1 3 1 1 1 2 5 1 3 2 2 1] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1338_210325_cellpose\n",
      "set  19 of 36\n",
      "1338 210805 002 LM\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(80, 8, 3) (18, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n",
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 356.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 cells are visually driven, \n",
      "        proportion 0.71 out of 80 cells\n",
      "73 cells are image driven - with overlap between images, \n",
      "        proportion 0.11 out of 640 cell-stim combos. \n",
      "        1-N image evokes resp from [18  6  9 11  5  7  4 13] cells\n",
      "img driven cells are driven by [1 5 1 1 3 3 3 2 1 2 1 1 2 1 2 2 1 1 1 2 3 1 4 1 1 1 2 2 1 4 3 1 1 5 1 3 1\n",
      " 2] images\n",
      "Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1338_210805_cellpose\n",
      "set  20 of 36\n",
      "1339 210908 003 LM\n",
      "set  20 of 36\n",
      "1339 210908 003\n",
      "waiting for tif\n",
      "set  20 of 36\n",
      "1339 210908 003\n",
      "waiting for tif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     \u001b[39m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Z:/All_Staff/home/lan/Data/2P_images/mat_inter/LM_i1339_210908_cellpose\\\\resp_base_trialwise.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ll357\\Documents\\inter\\scripts\\ipynb\\vis_driven.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     dir_sub \u001b[39m=\u001b[39m area \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_i\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mouse \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m date \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_cellpose\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     dfof_trialwise \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mloadmat(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dir_inter, dir_sub, \u001b[39m'\u001b[39;49m\u001b[39mresp_base_trialwise\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.mat\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m# dir_sub[:-7] delete caiman in dir_sub\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     f, opened \u001b[39m=\u001b[39m _open_file(file_like, appendmat, mode)\n\u001b[0;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     44\u001b[0m         file_like \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Z:/All_Staff/home/lan/Data/2P_images/mat_inter/LM_i1339_210908_cellpose\\\\resp_base_trialwise.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     \u001b[39m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Z:/All_Staff/home/lan/Data/2P_images/mat_inter/LM_i1339_210908\\\\resp_base_trialwise.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ll357\\Documents\\inter\\scripts\\ipynb\\vis_driven.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     dir_sub \u001b[39m=\u001b[39m area \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_i\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mouse \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m date \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     dfof_trialwise \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mloadmat(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dir_inter, dir_sub, \u001b[39m'\u001b[39;49m\u001b[39mresp_base_trialwise\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.mat\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m# dir_sub[:-7] delete caiman in dir_sub\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     f, opened \u001b[39m=\u001b[39m _open_file(file_like, appendmat, mode)\n\u001b[0;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ll357\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     44\u001b[0m         file_like \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Z:/All_Staff/home/lan/Data/2P_images/mat_inter/LM_i1339_210908\\\\resp_base_trialwise.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ll357\\Documents\\inter\\scripts\\ipynb\\vis_driven.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(mouse, date, irun)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mwaiting for tif\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m60\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# clear_output(wait=True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ll357/Documents/inter/scripts/ipynb/vis_driven.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir_inter = r'Z:\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter/'.replace('\\\\', '/')\n",
    "dir_file = dir_inter + 'adp_dataset_master.xlsx'\n",
    "data_info = pd.read_excel(dir_file)\n",
    "data_info.head()\n",
    "\n",
    "meta = data_info[(data_info.paradigm == 'grating') & ((data_info.area == 'LM') | (data_info.area == 'LI'))]\n",
    "meta.area.value_counts()\n",
    "\n",
    "nset = meta.shape[0]\n",
    "for i in np.arange(nset):\n",
    "    # clear_output(wait=True)\n",
    "    print('set ', i+1, 'of', nset)\n",
    "    mouse = meta.iloc[i].mouse.astype(str)\n",
    "    date = meta.iloc[i].date.astype(str)\n",
    "    area = meta.iloc[i].area\n",
    "    irun = '00' + meta.iloc[i].num.astype(int).astype(str)\n",
    "    print(mouse, date, irun, area)\n",
    "\n",
    "    ## check if resp_base_trialwise exists\n",
    "    ## load data\n",
    "    while True:\n",
    "        try:\n",
    "            try:\n",
    "                dir_sub = area + '_i' + mouse + '_' + date + '_cellpose'\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "            except:\n",
    "                dir_sub = area + '_i' + mouse + '_' + date + ''\n",
    "                dfof_trialwise = scipy.io.loadmat(os.path.join(dir_inter, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "            break\n",
    "        except:\n",
    "            print('set ', i+1, 'of', nset)\n",
    "            print(mouse, date, irun)\n",
    "            print('waiting for mat')\n",
    "            time.sleep(60)\n",
    "            # clear_output(wait=True)\n",
    "            continue\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "        mode = 'only one isi'\n",
    "        print(f'mode is {mode} (only one isi, grat_SF or bunny)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "        dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "        dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "    if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "        mode = 'grat_8ori_3isi'\n",
    "        print(f'mode is {mode} (grating with 8 orientations and 3 ISI)')\n",
    "        print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "        dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "        dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "        print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')\n",
    "\n",
    "    ## stats\n",
    "    if mode == 'only one isi':\n",
    "        print(mode)\n",
    "\n",
    "        ncell = dfof_ad_trial.shape[0]\n",
    "        nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base_trial[icell, istim]\n",
    "                stim_cell = dfof_ad_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            p_anova[icell] = p_anova_cell\n",
    "            _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "    elif mode == 'grat_8ori_3isi':\n",
    "        print(mode)\n",
    "\n",
    "        ncell = dfof_tg_trial.shape[0]\n",
    "        nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "        ## according to Ohki 2020\n",
    "        p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "        p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "        p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "        evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "        for icell in tqdm(np.arange(ncell)):\n",
    "            base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "            stim_cell_anova = [] \n",
    "            for istim in np.arange(nstim):\n",
    "                stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "                base_cell = dfof_base2_trial[icell, istim]\n",
    "                stim_cell = dfof_tg_trial[icell, istim]\n",
    "                _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "                p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "                evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "                evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "                evoked[icell, istim] = evoked_i\n",
    "            \n",
    "            _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            p_anova[icell] = p_anova_cell\n",
    "            _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "            p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "    # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "    p_sig = 0.05\n",
    "    vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "    print(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "        proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "    # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "    img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "    print(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "        proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "        1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "    t = np.sum(img_driven, axis=1)\n",
    "    print(f'img driven cells are driven by {t[t>0]} images')\n",
    "\n",
    "    ## save\n",
    "    vis_driven_re = {}\n",
    "    vis_driven_re['p_anova'] = p_anova\n",
    "    vis_driven_re['p_kruskal'] = p_kruskal\n",
    "    vis_driven_re['p_ttest'] = p_ttest\n",
    "    vis_driven_re['evoked'] = evoked\n",
    "    vis_driven_re['p_sig'] = p_sig\n",
    "    vis_driven_re['vis_driven'] = vis_driven\n",
    "    vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "    os.chdir(os.path.join(dir_inter, dir_sub))\n",
    "    print(os.getcwd())\n",
    "    with open('vis_driven.pickle', 'wb') as f:\n",
    "        pickle.dump(vis_driven_re, f)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6659cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323 200721\n",
      "mode is grat_8ori_3isi (grating with 8 orientations and 3 ISI)\n",
      "(39, 8, 3) (17, 1)\n",
      "to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \n",
      " 8 possible target orientations will cover all needed cells\n"
     ]
    }
   ],
   "source": [
    "# # meta = pd.read_excel(mat_inter_path + 'adp_dataset_master.xlsx')\n",
    "\n",
    "# # date_str = str(200721)\n",
    "# # mouse_str = meta.loc[meta['date'] == int(date_str), 'mouse'].values#[0]\n",
    "# # area_str = meta.loc[meta['date'] == int(date_str), 'area'].values[0]\n",
    "# # if len(mouse_str) > 1:\n",
    "# #     print('duplicate dates with maybe different mouse. select which mouse?')\n",
    "# # else:\n",
    "# #     mouse_str = str(mouse_str[0])\n",
    "# # print(mouse_str, date_str)\n",
    "\n",
    "# try:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + '_cellpose'\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# except:\n",
    "#     dir_sub = area_str + '_i' + mouse_str + '_' + date_str + ''\n",
    "#     dfof_trialwise = scipy.io.loadmat(os.path.join(mat_inter_path, dir_sub, 'resp_base_trialwise' + '.mat')) # dir_sub[:-7] delete caiman in dir_sub\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 2: # if contains only one ISI, likely 250\n",
    "#     mode = 'only one isi'\n",
    "#     print(f'mode is {mode} (only one isi, grat_SF or bunny)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0].shape)\n",
    "#     dfof_ad_trial = dfof_trialwise['dfof_ad_trial'] # do not subtract baseline here: stim resp will be compared to base resp\n",
    "#     dfof_base_trial = dfof_trialwise['dfof_base_trial']\n",
    "\n",
    "# if len(dfof_trialwise['dfof_ad_trial'].shape) == 3: # if contains multiple ISI, likely inf-750-250\n",
    "#     mode = 'grat_8ori_3isi'\n",
    "#     print(f'mode is {mode} (grating with 8 orientations and 3 ISI)')\n",
    "#     print(dfof_trialwise['dfof_ad_trial'].shape, dfof_trialwise['dfof_ad_trial'][0,0,0].shape)\n",
    "#     dfof_tg_trial = dfof_trialwise['dfof_tg_trial'][:,:,0] # only use the first ISI, aka no adapter trials\n",
    "#     dfof_base2_trial = dfof_trialwise['dfof_base2_trial'][:,:,0]\n",
    "#     print('to find visually driven cells and image driven cells, we should take only no-adapter trials and use target response. \\n 8 possible target orientations will cover all needed cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b51367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grat_8ori_3isi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 345.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# if mode == 'only one isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_ad_trial.shape[0]\n",
    "#     nstim = dfof_ad_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_ad_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base_trial[icell, istim]\n",
    "#             stim_cell = dfof_ad_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell\n",
    "\n",
    "# elif mode == 'grat_8ori_3isi':\n",
    "#     print(mode)\n",
    "\n",
    "#     ncell = dfof_tg_trial.shape[0]\n",
    "#     nstim = dfof_tg_trial.shape[1]\n",
    "\n",
    "#     ## according to Ohki 2020\n",
    "#     p_anova = np.ones((ncell, 1)) * np.nan # anova -> visually driven cells,  \n",
    "#     p_kruskal = np.ones((ncell, 1)) * np.nan # t test -> certain image responsive cells,\n",
    "#     p_ttest = np.ones((ncell, nstim)) * np.nan\n",
    "#     evoked = np.ones((ncell, nstim)) * np.nan # amp thresh -> lower false positive rate\n",
    "\n",
    "#     for icell in tqdm(np.arange(ncell)):\n",
    "#         base_cell_anova = np.concatenate([dfof_base2_trial[icell, stim] for stim in range(nstim)])\n",
    "#         stim_cell_anova = [] \n",
    "#         for istim in np.arange(nstim):\n",
    "#             stim_cell_anova.append(np.array(dfof_tg_trial[icell, istim]).flatten())\n",
    "\n",
    "#             base_cell = dfof_base2_trial[icell, istim]\n",
    "#             stim_cell = dfof_tg_trial[icell, istim]\n",
    "#             _, p_ttest_i = stats.ttest_ind(base_cell.flatten(), stim_cell.flatten(), equal_var=False, alternative='less')\n",
    "#             p_ttest[icell, istim] = p_ttest_i\n",
    "\n",
    "#             evoked_cell = (stim_cell - base_cell) / (base_cell + 1e-7)\n",
    "#             evoked_i = np.mean(evoked_cell, axis=0) # trial averaged evoked resp\n",
    "#             evoked[icell, istim] = evoked_i\n",
    "        \n",
    "#         _, p_anova_cell = stats.f_oneway(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_anova[icell] = p_anova_cell\n",
    "#         _, p_kruskal_cell = stats.kruskal(np.array(base_cell_anova).flatten(), *stim_cell_anova)\n",
    "#         p_kruskal[icell] = p_kruskal_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395531aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 cells are visually driven, \n",
      "    proportion 0.67 out of 39 cells\n",
      "29 cells are image driven - with overlap between images, \n",
      "    proportion 0.09 out of 312 cell-stim combos. \n",
      "    1-N image evokes resp from [4 2 6 1 3 2 5 6] cells\n",
      "img driven cells are driven by [1 2 2 1 2 1 1 1 2 1 2 1 4 1 1 1 1 3 1] images\n"
     ]
    }
   ],
   "source": [
    "# # visually driven cells: pass (anova OR kruskal) AND amp threshold for >=1 image\n",
    "# p_sig = 0.05\n",
    "# vis_driven = ((p_anova < p_sig) | (p_kruskal < p_sig)) & (sum(evoked.T > 0.1) > 0).reshape(-1, 1)\n",
    "# print(f'{vis_driven.sum()} cells are visually driven, \\n\\\n",
    "#     proportion {np.round(vis_driven.sum()/ncell, 2)} out of {ncell} cells')\n",
    "\n",
    "# # cells responsive to image i: pass visually driven (anova OR kruskal) AND t-test AND amp threshold for *this* image\n",
    "# img_driven = vis_driven & (p_ttest < p_sig) & (evoked > 0.1)\n",
    "# print(f'{img_driven.sum()} cells are image driven - with overlap between images, \\n\\\n",
    "#     proportion {np.round(img_driven.sum() / (ncell*nstim), 2)} out of {ncell*nstim} cell-stim combos. \\n\\\n",
    "#     1-N image evokes resp from {np.sum(img_driven, axis=0)} cells')\n",
    "\n",
    "# t = np.sum(img_driven, axis=1)\n",
    "# print(f'img driven cells are driven by {t[t>0]} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabf9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\duhs-user-nc1.dhe.duke.edu\\dusom_glickfeldlab\\All_Staff\\home\\lan\\Data\\2P_images\\mat_inter\\LM_i1323_200721\n"
     ]
    }
   ],
   "source": [
    "# vis_driven_re = {}\n",
    "# vis_driven_re['p_anova'] = p_anova\n",
    "# vis_driven_re['p_kruskal'] = p_kruskal\n",
    "# vis_driven_re['p_ttest'] = p_ttest\n",
    "# vis_driven_re['evoked'] = evoked\n",
    "# vis_driven_re['p_sig'] = p_sig\n",
    "# vis_driven_re['vis_driven'] = vis_driven\n",
    "# vis_driven_re['img_driven'] = img_driven\n",
    "\n",
    "# os.chdir(os.path.join(mat_inter_path, dir_sub))\n",
    "# print(os.getcwd())\n",
    "\n",
    "# with open('vis_driven.pickle', 'wb') as f:\n",
    "#     pickle.dump(vis_driven_re, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "654a1d97444558a991daa59b50de40303e0e66ccc3f29b4958db12481daba1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
